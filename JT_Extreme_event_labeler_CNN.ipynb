{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Union events across towers |  Load Events!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Tuple, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98668b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tower</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>TempC_015m</th>\n",
       "      <th>TempC_030m</th>\n",
       "      <th>RelHum_015m</th>\n",
       "      <th>AbsHum_015m</th>\n",
       "      <th>WSpdMph_015m</th>\n",
       "      <th>WSpdMph_030m</th>\n",
       "      <th>PkWSpdMph_015m</th>\n",
       "      <th>PkWSpdMph_030m</th>\n",
       "      <th>VSSpdMph_015m</th>\n",
       "      <th>VSSpdMph_030m</th>\n",
       "      <th>BarPresMb_015m</th>\n",
       "      <th>Sigma_015m</th>\n",
       "      <th>Sigma_030m</th>\n",
       "      <th>SigPhi_015m</th>\n",
       "      <th>SigPhi_030m</th>\n",
       "      <th>WDir_015m</th>\n",
       "      <th>WDir_030m</th>\n",
       "      <th>PrecipIn_015m</th>\n",
       "      <th>event_E3_LowTemp_lt0</th>\n",
       "      <th>event_E4_HighWind_Peak_gt25</th>\n",
       "      <th>event_E5_LowWind_lt2</th>\n",
       "      <th>event_E6_HighTemp_gt24</th>\n",
       "      <th>SolarRadWm2_015m</th>\n",
       "      <th>TempC_002m</th>\n",
       "      <th>TempC_035m</th>\n",
       "      <th>TempC_060m</th>\n",
       "      <th>RelHum_002m</th>\n",
       "      <th>AbsHum_002m</th>\n",
       "      <th>WSpdMph_035m</th>\n",
       "      <th>WSpdMph_060m</th>\n",
       "      <th>PkWSpdMph_035m</th>\n",
       "      <th>PkWSpdMph_060m</th>\n",
       "      <th>VSSpdMph_060m</th>\n",
       "      <th>SolarRadWm2_002m</th>\n",
       "      <th>BarPresMb_002m</th>\n",
       "      <th>Sigma_035m</th>\n",
       "      <th>Sigma_060m</th>\n",
       "      <th>SigPhi_060m</th>\n",
       "      <th>WDir_035m</th>\n",
       "      <th>WDir_060m</th>\n",
       "      <th>PrecipIn_002m</th>\n",
       "      <th>TempC_010m</th>\n",
       "      <th>RelHum_010m</th>\n",
       "      <th>AbsHum_010m</th>\n",
       "      <th>WSpdMph_010m</th>\n",
       "      <th>PkWSpdMph_010m</th>\n",
       "      <th>VSSpdMph_010m</th>\n",
       "      <th>SolarRadWm2_010m</th>\n",
       "      <th>BarPresMb_010m</th>\n",
       "      <th>Sigma_010m</th>\n",
       "      <th>SigPhi_010m</th>\n",
       "      <th>WDir_010m</th>\n",
       "      <th>PrecipIn_010m</th>\n",
       "      <th>TempC_025m</th>\n",
       "      <th>WSpdMph_025m</th>\n",
       "      <th>PkWSpdMph_025m</th>\n",
       "      <th>VSSpdMph_025m</th>\n",
       "      <th>Sigma_025m</th>\n",
       "      <th>SigPhi_025m</th>\n",
       "      <th>WDir_025m</th>\n",
       "      <th>TempC_033m</th>\n",
       "      <th>WSpdMph_033m</th>\n",
       "      <th>PkWSpdMph_033m</th>\n",
       "      <th>VSSpdMph_033m</th>\n",
       "      <th>Sigma_033m</th>\n",
       "      <th>SigPhi_033m</th>\n",
       "      <th>WDir_033m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TOWA</td>\n",
       "      <td>2017-01-01 05:00:00+00:00</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3.6</td>\n",
       "      <td>97.4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>5.9</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>985.30000</td>\n",
       "      <td>26.5</td>\n",
       "      <td>15.5</td>\n",
       "      <td>18.9</td>\n",
       "      <td>12.6</td>\n",
       "      <td>268.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>0.015748</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TOWB</td>\n",
       "      <td>2017-01-01 05:00:00+00:00</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>3.8</td>\n",
       "      <td>99.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>986.40000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TOWD</td>\n",
       "      <td>2017-01-01 05:00:00+00:00</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.04474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>986.40000</td>\n",
       "      <td>26.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>257.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>96.7</td>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.8</td>\n",
       "      <td>-0.15659</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>986.4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>9.4</td>\n",
       "      <td>272.7</td>\n",
       "      <td>275.3</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TOWF</td>\n",
       "      <td>2017-01-01 05:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TOWS</td>\n",
       "      <td>2017-01-01 05:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.366668</td>\n",
       "      <td>9.6</td>\n",
       "      <td>15.3</td>\n",
       "      <td>0.542</td>\n",
       "      <td>13.9</td>\n",
       "      <td>8.3</td>\n",
       "      <td>277.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TOWY</td>\n",
       "      <td>2017-01-01 05:00:00+00:00</td>\n",
       "      <td>4.166666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.59000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>982.92926</td>\n",
       "      <td>17.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>274.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.777777</td>\n",
       "      <td>8.8</td>\n",
       "      <td>15.3</td>\n",
       "      <td>-0.182</td>\n",
       "      <td>16.7</td>\n",
       "      <td>11.2</td>\n",
       "      <td>274.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TOWA</td>\n",
       "      <td>2017-01-01 05:15:00+00:00</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3.6</td>\n",
       "      <td>97.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>4.7</td>\n",
       "      <td>6.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>985.30000</td>\n",
       "      <td>19.3</td>\n",
       "      <td>13.9</td>\n",
       "      <td>14.3</td>\n",
       "      <td>9.8</td>\n",
       "      <td>252.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.011811</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TOWB</td>\n",
       "      <td>2017-01-01 05:15:00+00:00</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>3.7</td>\n",
       "      <td>99.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>986.40000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TOWD</td>\n",
       "      <td>2017-01-01 05:15:00+00:00</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.5</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.06711</td>\n",
       "      <td>NaN</td>\n",
       "      <td>986.40000</td>\n",
       "      <td>32.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>233.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>96.7</td>\n",
       "      <td>6.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>8.7</td>\n",
       "      <td>-0.02237</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>986.4</td>\n",
       "      <td>21.2</td>\n",
       "      <td>16.2</td>\n",
       "      <td>10.6</td>\n",
       "      <td>258.4</td>\n",
       "      <td>266.4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TOWF</td>\n",
       "      <td>2017-01-01 05:15:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TOWS</td>\n",
       "      <td>2017-01-01 05:15:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.494445</td>\n",
       "      <td>11.3</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.516</td>\n",
       "      <td>8.4</td>\n",
       "      <td>6.7</td>\n",
       "      <td>272.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TOWY</td>\n",
       "      <td>2017-01-01 05:15:00+00:00</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.14000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>982.79380</td>\n",
       "      <td>15.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>260.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.944444</td>\n",
       "      <td>7.9</td>\n",
       "      <td>15.3</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>14.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>263.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TOWA</td>\n",
       "      <td>2017-01-01 05:30:00+00:00</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3.7</td>\n",
       "      <td>97.4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>-0.20000</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>985.20000</td>\n",
       "      <td>25.3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>11.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>0.011811</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TOWB</td>\n",
       "      <td>2017-01-01 05:30:00+00:00</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>3.8</td>\n",
       "      <td>99.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>986.30000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TOWD</td>\n",
       "      <td>2017-01-01 05:30:00+00:00</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>986.30000</td>\n",
       "      <td>25.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>97.1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.02237</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>986.3</td>\n",
       "      <td>15.3</td>\n",
       "      <td>12.1</td>\n",
       "      <td>10.4</td>\n",
       "      <td>248.9</td>\n",
       "      <td>254.7</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TOWF</td>\n",
       "      <td>2017-01-01 05:30:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TOWS</td>\n",
       "      <td>2017-01-01 05:30:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.527777</td>\n",
       "      <td>10.8</td>\n",
       "      <td>16.3</td>\n",
       "      <td>0.722</td>\n",
       "      <td>9.1</td>\n",
       "      <td>6.8</td>\n",
       "      <td>270.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TOWY</td>\n",
       "      <td>2017-01-01 05:30:00+00:00</td>\n",
       "      <td>4.388890</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.37000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>982.75995</td>\n",
       "      <td>11.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>258.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.2</td>\n",
       "      <td>15.3</td>\n",
       "      <td>-0.267</td>\n",
       "      <td>12.4</td>\n",
       "      <td>11.3</td>\n",
       "      <td>263.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TOWA</td>\n",
       "      <td>2017-01-01 05:45:00+00:00</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>3.7</td>\n",
       "      <td>97.4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.8</td>\n",
       "      <td>-0.20000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>985.00000</td>\n",
       "      <td>29.4</td>\n",
       "      <td>16.6</td>\n",
       "      <td>14.4</td>\n",
       "      <td>8.3</td>\n",
       "      <td>268.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TOWB</td>\n",
       "      <td>2017-01-01 05:45:00+00:00</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>3.9</td>\n",
       "      <td>99.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>986.10000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tower                  timestamp  TempC_015m  TempC_030m  RelHum_015m  \\\n",
       "0   TOWA  2017-01-01 05:00:00+00:00    3.600000         3.6         97.4   \n",
       "1   TOWB  2017-01-01 05:00:00+00:00    3.900000         3.8         99.9   \n",
       "2   TOWD  2017-01-01 05:00:00+00:00    3.900000         NaN         97.2   \n",
       "3   TOWF  2017-01-01 05:00:00+00:00         NaN         NaN          NaN   \n",
       "4   TOWS  2017-01-01 05:00:00+00:00         NaN         NaN          NaN   \n",
       "5   TOWY  2017-01-01 05:00:00+00:00    4.166666         NaN         95.7   \n",
       "6   TOWA  2017-01-01 05:15:00+00:00    3.600000         3.6         97.3   \n",
       "7   TOWB  2017-01-01 05:15:00+00:00    3.800000         3.7         99.9   \n",
       "8   TOWD  2017-01-01 05:15:00+00:00    3.900000         NaN         97.5   \n",
       "9   TOWF  2017-01-01 05:15:00+00:00         NaN         NaN          NaN   \n",
       "10  TOWS  2017-01-01 05:15:00+00:00         NaN         NaN          NaN   \n",
       "11  TOWY  2017-01-01 05:15:00+00:00    4.333333         NaN         96.0   \n",
       "12  TOWA  2017-01-01 05:30:00+00:00    3.600000         3.7         97.4   \n",
       "13  TOWB  2017-01-01 05:30:00+00:00    3.900000         3.8         99.9   \n",
       "14  TOWD  2017-01-01 05:30:00+00:00    3.900000         NaN         98.0   \n",
       "15  TOWF  2017-01-01 05:30:00+00:00         NaN         NaN          NaN   \n",
       "16  TOWS  2017-01-01 05:30:00+00:00         NaN         NaN          NaN   \n",
       "17  TOWY  2017-01-01 05:30:00+00:00    4.388890         NaN         96.0   \n",
       "18  TOWA  2017-01-01 05:45:00+00:00    3.700000         3.7         97.4   \n",
       "19  TOWB  2017-01-01 05:45:00+00:00    3.900000         3.9         99.9   \n",
       "\n",
       "    AbsHum_015m  WSpdMph_015m  WSpdMph_030m  PkWSpdMph_015m  PkWSpdMph_030m  \\\n",
       "0           6.0           2.2           4.4             5.9            10.2   \n",
       "1           NaN           NaN           NaN             NaN             NaN   \n",
       "2           6.1           2.2           NaN             5.5             NaN   \n",
       "3           NaN           NaN           NaN             NaN             NaN   \n",
       "4           NaN           NaN           NaN             NaN             NaN   \n",
       "5           NaN           7.6           NaN            13.1             NaN   \n",
       "6           6.0           2.4           4.7             6.7             7.7   \n",
       "7           NaN           NaN           NaN             NaN             NaN   \n",
       "8           6.1           2.1           NaN             6.2             NaN   \n",
       "9           NaN           NaN           NaN             NaN             NaN   \n",
       "10          NaN           NaN           NaN             NaN             NaN   \n",
       "11          NaN           6.9           NaN            11.4             NaN   \n",
       "12          6.0           2.8           4.3             6.0             6.8   \n",
       "13          NaN           NaN           NaN             NaN             NaN   \n",
       "14          6.2           1.9           NaN             3.7             NaN   \n",
       "15          NaN           NaN           NaN             NaN             NaN   \n",
       "16          NaN           NaN           NaN             NaN             NaN   \n",
       "17          NaN           7.4           NaN            14.9             NaN   \n",
       "18          6.0           2.5           4.2             5.1             6.8   \n",
       "19          NaN           NaN           NaN             NaN             NaN   \n",
       "\n",
       "    VSSpdMph_015m  VSSpdMph_030m  BarPresMb_015m  Sigma_015m  Sigma_030m  \\\n",
       "0         0.00000      -0.100000       985.30000        26.5        15.5   \n",
       "1             NaN            NaN       986.40000         NaN         NaN   \n",
       "2        -0.04474            NaN       986.40000        26.3         NaN   \n",
       "3             NaN            NaN             NaN         NaN         NaN   \n",
       "4             NaN            NaN             NaN         NaN         NaN   \n",
       "5        -0.59000            NaN       982.92926        17.5         NaN   \n",
       "6         0.00000      -0.100000       985.30000        19.3        13.9   \n",
       "7             NaN            NaN       986.40000         NaN         NaN   \n",
       "8        -0.06711            NaN       986.40000        32.7         NaN   \n",
       "9             NaN            NaN             NaN         NaN         NaN   \n",
       "10            NaN            NaN             NaN         NaN         NaN   \n",
       "11       -0.14000            NaN       982.79380        15.3         NaN   \n",
       "12       -0.20000       0.000064       985.20000        25.3        15.0   \n",
       "13            NaN            NaN       986.30000         NaN         NaN   \n",
       "14        0.02237            NaN       986.30000        25.5         NaN   \n",
       "15            NaN            NaN             NaN         NaN         NaN   \n",
       "16            NaN            NaN             NaN         NaN         NaN   \n",
       "17       -0.37000            NaN       982.75995        11.5         NaN   \n",
       "18       -0.20000      -0.100000       985.00000        29.4        16.6   \n",
       "19            NaN            NaN       986.10000         NaN         NaN   \n",
       "\n",
       "    SigPhi_015m  SigPhi_030m  WDir_015m  WDir_030m  PrecipIn_015m  \\\n",
       "0          18.9         12.6      268.0      274.0       0.015748   \n",
       "1           NaN          NaN        NaN        NaN            NaN   \n",
       "2          12.6          NaN      257.6        NaN            NaN   \n",
       "3           NaN          NaN        NaN        NaN            NaN   \n",
       "4           NaN          NaN        NaN        NaN            NaN   \n",
       "5           9.0          NaN      274.0        NaN       0.010000   \n",
       "6          14.3          9.8      252.0      264.0       0.011811   \n",
       "7           NaN          NaN        NaN        NaN            NaN   \n",
       "8          14.2          NaN      233.2        NaN            NaN   \n",
       "9           NaN          NaN        NaN        NaN            NaN   \n",
       "10          NaN          NaN        NaN        NaN            NaN   \n",
       "11          7.1          NaN      260.0        NaN       0.000000   \n",
       "12         13.6         11.0      255.0      260.0       0.011811   \n",
       "13          NaN          NaN        NaN        NaN            NaN   \n",
       "14         14.5          NaN      219.6        NaN            NaN   \n",
       "15          NaN          NaN        NaN        NaN            NaN   \n",
       "16          NaN          NaN        NaN        NaN            NaN   \n",
       "17          7.1          NaN      258.0        NaN       0.010000   \n",
       "18         14.4          8.3      268.0      263.0       0.007874   \n",
       "19          NaN          NaN        NaN        NaN            NaN   \n",
       "\n",
       "    event_E3_LowTemp_lt0  event_E4_HighWind_Peak_gt25  event_E5_LowWind_lt2  \\\n",
       "0                  False                        False                 False   \n",
       "1                  False                        False                 False   \n",
       "2                  False                        False                 False   \n",
       "3                  False                        False                 False   \n",
       "4                  False                        False                 False   \n",
       "5                  False                        False                 False   \n",
       "6                  False                        False                 False   \n",
       "7                  False                        False                 False   \n",
       "8                  False                        False                 False   \n",
       "9                  False                        False                 False   \n",
       "10                 False                        False                 False   \n",
       "11                 False                        False                 False   \n",
       "12                 False                        False                 False   \n",
       "13                 False                        False                 False   \n",
       "14                 False                        False                 False   \n",
       "15                 False                        False                 False   \n",
       "16                 False                        False                 False   \n",
       "17                 False                        False                 False   \n",
       "18                 False                        False                 False   \n",
       "19                 False                        False                 False   \n",
       "\n",
       "    event_E6_HighTemp_gt24  SolarRadWm2_015m  TempC_002m  TempC_035m  \\\n",
       "0                    False               NaN         NaN         NaN   \n",
       "1                    False               NaN         NaN         NaN   \n",
       "2                    False               NaN         3.9         3.8   \n",
       "3                    False               NaN         NaN         NaN   \n",
       "4                    False               NaN         NaN         NaN   \n",
       "5                    False               0.0         NaN         NaN   \n",
       "6                    False               NaN         NaN         NaN   \n",
       "7                    False               NaN         NaN         NaN   \n",
       "8                    False               NaN         3.9         3.8   \n",
       "9                    False               NaN         NaN         NaN   \n",
       "10                   False               NaN         NaN         NaN   \n",
       "11                   False               0.0         NaN         NaN   \n",
       "12                   False               NaN         NaN         NaN   \n",
       "13                   False               NaN         NaN         NaN   \n",
       "14                   False               NaN         3.9         3.9   \n",
       "15                   False               NaN         NaN         NaN   \n",
       "16                   False               NaN         NaN         NaN   \n",
       "17                   False               0.0         NaN         NaN   \n",
       "18                   False               NaN         NaN         NaN   \n",
       "19                   False               NaN         NaN         NaN   \n",
       "\n",
       "    TempC_060m  RelHum_002m  AbsHum_002m  WSpdMph_035m  WSpdMph_060m  \\\n",
       "0          NaN          NaN          NaN           NaN           NaN   \n",
       "1          NaN          NaN          NaN           NaN           NaN   \n",
       "2          3.7         96.7          6.1           3.0           4.6   \n",
       "3          NaN          NaN          NaN           NaN           NaN   \n",
       "4          NaN          NaN          NaN           NaN           NaN   \n",
       "5          NaN          NaN          NaN           NaN           NaN   \n",
       "6          NaN          NaN          NaN           NaN           NaN   \n",
       "7          NaN          NaN          NaN           NaN           NaN   \n",
       "8          3.7         96.7          6.1           3.3           5.0   \n",
       "9          NaN          NaN          NaN           NaN           NaN   \n",
       "10         NaN          NaN          NaN           NaN           NaN   \n",
       "11         NaN          NaN          NaN           NaN           NaN   \n",
       "12         NaN          NaN          NaN           NaN           NaN   \n",
       "13         NaN          NaN          NaN           NaN           NaN   \n",
       "14         3.8         97.1          6.1           3.4           4.6   \n",
       "15         NaN          NaN          NaN           NaN           NaN   \n",
       "16         NaN          NaN          NaN           NaN           NaN   \n",
       "17         NaN          NaN          NaN           NaN           NaN   \n",
       "18         NaN          NaN          NaN           NaN           NaN   \n",
       "19         NaN          NaN          NaN           NaN           NaN   \n",
       "\n",
       "    PkWSpdMph_035m  PkWSpdMph_060m  VSSpdMph_060m  SolarRadWm2_002m  \\\n",
       "0              NaN             NaN            NaN               NaN   \n",
       "1              NaN             NaN            NaN               NaN   \n",
       "2              7.3             7.8       -0.15659              -2.4   \n",
       "3              NaN             NaN            NaN               NaN   \n",
       "4              NaN             NaN            NaN               NaN   \n",
       "5              NaN             NaN            NaN               NaN   \n",
       "6              NaN             NaN            NaN               NaN   \n",
       "7              NaN             NaN            NaN               NaN   \n",
       "8              7.1             8.7       -0.02237              -1.3   \n",
       "9              NaN             NaN            NaN               NaN   \n",
       "10             NaN             NaN            NaN               NaN   \n",
       "11             NaN             NaN            NaN               NaN   \n",
       "12             NaN             NaN            NaN               NaN   \n",
       "13             NaN             NaN            NaN               NaN   \n",
       "14             6.0             7.1        0.02237              -1.1   \n",
       "15             NaN             NaN            NaN               NaN   \n",
       "16             NaN             NaN            NaN               NaN   \n",
       "17             NaN             NaN            NaN               NaN   \n",
       "18             NaN             NaN            NaN               NaN   \n",
       "19             NaN             NaN            NaN               NaN   \n",
       "\n",
       "    BarPresMb_002m  Sigma_035m  Sigma_060m  SigPhi_060m  WDir_035m  WDir_060m  \\\n",
       "0              NaN         NaN         NaN          NaN        NaN        NaN   \n",
       "1              NaN         NaN         NaN          NaN        NaN        NaN   \n",
       "2            986.4        18.0        14.2          9.4      272.7      275.3   \n",
       "3              NaN         NaN         NaN          NaN        NaN        NaN   \n",
       "4              NaN         NaN         NaN          NaN        NaN        NaN   \n",
       "5              NaN         NaN         NaN          NaN        NaN        NaN   \n",
       "6              NaN         NaN         NaN          NaN        NaN        NaN   \n",
       "7              NaN         NaN         NaN          NaN        NaN        NaN   \n",
       "8            986.4        21.2        16.2         10.6      258.4      266.4   \n",
       "9              NaN         NaN         NaN          NaN        NaN        NaN   \n",
       "10             NaN         NaN         NaN          NaN        NaN        NaN   \n",
       "11             NaN         NaN         NaN          NaN        NaN        NaN   \n",
       "12             NaN         NaN         NaN          NaN        NaN        NaN   \n",
       "13             NaN         NaN         NaN          NaN        NaN        NaN   \n",
       "14           986.3        15.3        12.1         10.4      248.9      254.7   \n",
       "15             NaN         NaN         NaN          NaN        NaN        NaN   \n",
       "16             NaN         NaN         NaN          NaN        NaN        NaN   \n",
       "17             NaN         NaN         NaN          NaN        NaN        NaN   \n",
       "18             NaN         NaN         NaN          NaN        NaN        NaN   \n",
       "19             NaN         NaN         NaN          NaN        NaN        NaN   \n",
       "\n",
       "    PrecipIn_002m  TempC_010m  RelHum_010m  AbsHum_010m  WSpdMph_010m  \\\n",
       "0             NaN         NaN          NaN          NaN           NaN   \n",
       "1             NaN         NaN          NaN          NaN           NaN   \n",
       "2            0.02         NaN          NaN          NaN           NaN   \n",
       "3             NaN         NaN          NaN          NaN           NaN   \n",
       "4             NaN         NaN          NaN          NaN           NaN   \n",
       "5             NaN         NaN          NaN          NaN           NaN   \n",
       "6             NaN         NaN          NaN          NaN           NaN   \n",
       "7             NaN         NaN          NaN          NaN           NaN   \n",
       "8            0.01         NaN          NaN          NaN           NaN   \n",
       "9             NaN         NaN          NaN          NaN           NaN   \n",
       "10            NaN         NaN          NaN          NaN           NaN   \n",
       "11            NaN         NaN          NaN          NaN           NaN   \n",
       "12            NaN         NaN          NaN          NaN           NaN   \n",
       "13            NaN         NaN          NaN          NaN           NaN   \n",
       "14           0.01         NaN          NaN          NaN           NaN   \n",
       "15            NaN         NaN          NaN          NaN           NaN   \n",
       "16            NaN         NaN          NaN          NaN           NaN   \n",
       "17            NaN         NaN          NaN          NaN           NaN   \n",
       "18            NaN         NaN          NaN          NaN           NaN   \n",
       "19            NaN         NaN          NaN          NaN           NaN   \n",
       "\n",
       "    PkWSpdMph_010m  VSSpdMph_010m  SolarRadWm2_010m  BarPresMb_010m  \\\n",
       "0              NaN            NaN               NaN             NaN   \n",
       "1              NaN            NaN               NaN             NaN   \n",
       "2              NaN            NaN               NaN             NaN   \n",
       "3              NaN            NaN               NaN             NaN   \n",
       "4              NaN            NaN               NaN             NaN   \n",
       "5              NaN            NaN               NaN             NaN   \n",
       "6              NaN            NaN               NaN             NaN   \n",
       "7              NaN            NaN               NaN             NaN   \n",
       "8              NaN            NaN               NaN             NaN   \n",
       "9              NaN            NaN               NaN             NaN   \n",
       "10             NaN            NaN               NaN             NaN   \n",
       "11             NaN            NaN               NaN             NaN   \n",
       "12             NaN            NaN               NaN             NaN   \n",
       "13             NaN            NaN               NaN             NaN   \n",
       "14             NaN            NaN               NaN             NaN   \n",
       "15             NaN            NaN               NaN             NaN   \n",
       "16             NaN            NaN               NaN             NaN   \n",
       "17             NaN            NaN               NaN             NaN   \n",
       "18             NaN            NaN               NaN             NaN   \n",
       "19             NaN            NaN               NaN             NaN   \n",
       "\n",
       "    Sigma_010m  SigPhi_010m  WDir_010m  PrecipIn_010m  TempC_025m  \\\n",
       "0          NaN          NaN        NaN            NaN         NaN   \n",
       "1          NaN          NaN        NaN            NaN         NaN   \n",
       "2          NaN          NaN        NaN            NaN         NaN   \n",
       "3          NaN          NaN        NaN            NaN         NaN   \n",
       "4          NaN          NaN        NaN            NaN    3.366668   \n",
       "5          NaN          NaN        NaN            NaN         NaN   \n",
       "6          NaN          NaN        NaN            NaN         NaN   \n",
       "7          NaN          NaN        NaN            NaN         NaN   \n",
       "8          NaN          NaN        NaN            NaN         NaN   \n",
       "9          NaN          NaN        NaN            NaN         NaN   \n",
       "10         NaN          NaN        NaN            NaN    3.494445   \n",
       "11         NaN          NaN        NaN            NaN         NaN   \n",
       "12         NaN          NaN        NaN            NaN         NaN   \n",
       "13         NaN          NaN        NaN            NaN         NaN   \n",
       "14         NaN          NaN        NaN            NaN         NaN   \n",
       "15         NaN          NaN        NaN            NaN         NaN   \n",
       "16         NaN          NaN        NaN            NaN    3.527777   \n",
       "17         NaN          NaN        NaN            NaN         NaN   \n",
       "18         NaN          NaN        NaN            NaN         NaN   \n",
       "19         NaN          NaN        NaN            NaN         NaN   \n",
       "\n",
       "    WSpdMph_025m  PkWSpdMph_025m  VSSpdMph_025m  Sigma_025m  SigPhi_025m  \\\n",
       "0            NaN             NaN            NaN         NaN          NaN   \n",
       "1            NaN             NaN            NaN         NaN          NaN   \n",
       "2            NaN             NaN            NaN         NaN          NaN   \n",
       "3            NaN             NaN            NaN         NaN          NaN   \n",
       "4            9.6            15.3          0.542        13.9          8.3   \n",
       "5            NaN             NaN            NaN         NaN          NaN   \n",
       "6            NaN             NaN            NaN         NaN          NaN   \n",
       "7            NaN             NaN            NaN         NaN          NaN   \n",
       "8            NaN             NaN            NaN         NaN          NaN   \n",
       "9            NaN             NaN            NaN         NaN          NaN   \n",
       "10          11.3            17.0          0.516         8.4          6.7   \n",
       "11           NaN             NaN            NaN         NaN          NaN   \n",
       "12           NaN             NaN            NaN         NaN          NaN   \n",
       "13           NaN             NaN            NaN         NaN          NaN   \n",
       "14           NaN             NaN            NaN         NaN          NaN   \n",
       "15           NaN             NaN            NaN         NaN          NaN   \n",
       "16          10.8            16.3          0.722         9.1          6.8   \n",
       "17           NaN             NaN            NaN         NaN          NaN   \n",
       "18           NaN             NaN            NaN         NaN          NaN   \n",
       "19           NaN             NaN            NaN         NaN          NaN   \n",
       "\n",
       "    WDir_025m  TempC_033m  WSpdMph_033m  PkWSpdMph_033m  VSSpdMph_033m  \\\n",
       "0         NaN         NaN           NaN             NaN            NaN   \n",
       "1         NaN         NaN           NaN             NaN            NaN   \n",
       "2         NaN         NaN           NaN             NaN            NaN   \n",
       "3         NaN         NaN           NaN             NaN            NaN   \n",
       "4       277.0         NaN           NaN             NaN            NaN   \n",
       "5         NaN    3.777777           8.8            15.3         -0.182   \n",
       "6         NaN         NaN           NaN             NaN            NaN   \n",
       "7         NaN         NaN           NaN             NaN            NaN   \n",
       "8         NaN         NaN           NaN             NaN            NaN   \n",
       "9         NaN         NaN           NaN             NaN            NaN   \n",
       "10      272.0         NaN           NaN             NaN            NaN   \n",
       "11        NaN    3.944444           7.9            15.3         -0.004   \n",
       "12        NaN         NaN           NaN             NaN            NaN   \n",
       "13        NaN         NaN           NaN             NaN            NaN   \n",
       "14        NaN         NaN           NaN             NaN            NaN   \n",
       "15        NaN         NaN           NaN             NaN            NaN   \n",
       "16      270.0         NaN           NaN             NaN            NaN   \n",
       "17        NaN    4.000000           8.2            15.3         -0.267   \n",
       "18        NaN         NaN           NaN             NaN            NaN   \n",
       "19        NaN         NaN           NaN             NaN            NaN   \n",
       "\n",
       "    Sigma_033m  SigPhi_033m  WDir_033m  \n",
       "0          NaN          NaN        NaN  \n",
       "1          NaN          NaN        NaN  \n",
       "2          NaN          NaN        NaN  \n",
       "3          NaN          NaN        NaN  \n",
       "4          NaN          NaN        NaN  \n",
       "5         16.7         11.2      274.0  \n",
       "6          NaN          NaN        NaN  \n",
       "7          NaN          NaN        NaN  \n",
       "8          NaN          NaN        NaN  \n",
       "9          NaN          NaN        NaN  \n",
       "10         NaN          NaN        NaN  \n",
       "11        14.8         10.8      263.0  \n",
       "12         NaN          NaN        NaN  \n",
       "13         NaN          NaN        NaN  \n",
       "14         NaN          NaN        NaN  \n",
       "15         NaN          NaN        NaN  \n",
       "16         NaN          NaN        NaN  \n",
       "17        12.4         11.3      263.0  \n",
       "18         NaN          NaN        NaN  \n",
       "19         NaN          NaN        NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "df = pd.read_csv(\"fully_labeled_weather_data_with_events.csv\")\n",
    "\n",
    "# 2 Move 'tower' and 'timestamp' to the first two columns\n",
    "cols = df.columns.tolist()\n",
    "priority_cols = ['tower', 'timestamp']\n",
    "remaining_cols = [c for c in cols if c not in priority_cols]\n",
    "df = df[priority_cols + remaining_cols]\n",
    "\n",
    "# Drop columns ending with '_min' or '_meets_duration'\n",
    "df = df.loc[:, ~df.columns.str.endswith(('_min', '_meets_duration'))]\n",
    "\n",
    "#remove these columns\n",
    "df = df.drop(columns=['event_count','active_events','event_durations', 'has_any_event'])\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "\n",
    "# Check the first few rows\n",
    "df.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f983e48",
   "metadata": {},
   "source": [
    "### EVENT SUMMARY:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ee7c29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Rows with more than two active events:\n",
      "        tower                  timestamp  true_event_count\n",
      "646309   TOWB  2020-01-28 12:30:00+00:00                 3\n",
      "1074314  TOWD  2022-02-09 18:00:00+00:00                 3\n",
      "\n",
      " Summary of towers with >2 events:\n",
      "  tower  true_event_count\n",
      "0  TOWB                 1\n",
      "1  TOWD                 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# List all boolean event columns\n",
    "event_cols = [\n",
    "    'event_E3_LowTemp_lt0',\n",
    "    'event_E4_HighWind_Peak_gt25',\n",
    "    'event_E5_LowWind_lt2',\n",
    "    'event_E6_HighTemp_gt24'\n",
    "]\n",
    "\n",
    "# Ensure the columns are boolean\n",
    "df[event_cols] = df[event_cols].astype(bool)\n",
    "\n",
    "# Count how many events are True per row\n",
    "df[\"true_event_count\"] = df[event_cols].sum(axis=1)\n",
    "\n",
    "# Filter: rows where more than 2 events are True simultaneously (per tower)\n",
    "multiple_events_df = df[df[\"true_event_count\"] > 2]\n",
    "\n",
    "# Optional: group by tower if you want to see which towers are affected\n",
    "tower_event_summary = multiple_events_df.groupby(\"tower\")[\"true_event_count\"].count().reset_index()\n",
    "\n",
    "print(\" Rows with more than two active events:\")\n",
    "print(multiple_events_df[[\"tower\", \"timestamp\", \"true_event_count\"]])\n",
    "\n",
    "print(\"\\n Summary of towers with >2 events:\")\n",
    "print(tower_event_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb519a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tower types: ['TOWA' 'TOWB' 'TOWD' 'TOWF' 'TOWS' 'TOWY']\n",
      "\n",
      "Example  TOWA DataFrame:\n",
      "   tower                  timestamp  TempC_015m  TempC_030m  RelHum_015m  \\\n",
      "0   TOWA  2017-01-01 05:00:00+00:00         3.6         3.6         97.4   \n",
      "6   TOWA  2017-01-01 05:15:00+00:00         3.6         3.6         97.3   \n",
      "12  TOWA  2017-01-01 05:30:00+00:00         3.6         3.7         97.4   \n",
      "18  TOWA  2017-01-01 05:45:00+00:00         3.7         3.7         97.4   \n",
      "24  TOWA  2017-01-01 06:00:00+00:00         3.8         3.8         97.3   \n",
      "\n",
      "    AbsHum_015m  WSpdMph_015m  WSpdMph_030m  PkWSpdMph_015m  PkWSpdMph_030m  \\\n",
      "0           6.0           2.2           4.4             5.9            10.2   \n",
      "6           6.0           2.4           4.7             6.7             7.7   \n",
      "12          6.0           2.8           4.3             6.0             6.8   \n",
      "18          6.0           2.5           4.2             5.1             6.8   \n",
      "24          6.0           2.2           4.0             4.2             6.3   \n",
      "\n",
      "    VSSpdMph_015m  VSSpdMph_030m  BarPresMb_015m  Sigma_015m  Sigma_030m  \\\n",
      "0             0.0      -0.100000           985.3        26.5        15.5   \n",
      "6             0.0      -0.100000           985.3        19.3        13.9   \n",
      "12           -0.2       0.000064           985.2        25.3        15.0   \n",
      "18           -0.2      -0.100000           985.0        29.4        16.6   \n",
      "24            0.0       0.100000           985.1        25.0        13.1   \n",
      "\n",
      "    SigPhi_015m  SigPhi_030m  WDir_015m  WDir_030m  PrecipIn_015m  \\\n",
      "0          18.9         12.6      268.0      274.0       0.015748   \n",
      "6          14.3          9.8      252.0      264.0       0.011811   \n",
      "12         13.6         11.0      255.0      260.0       0.011811   \n",
      "18         14.4          8.3      268.0      263.0       0.007874   \n",
      "24         14.9         10.8      268.0      274.0       0.007874   \n",
      "\n",
      "    event_E3_LowTemp_lt0  event_E4_HighWind_Peak_gt25  event_E5_LowWind_lt2  \\\n",
      "0                  False                        False                 False   \n",
      "6                  False                        False                 False   \n",
      "12                 False                        False                 False   \n",
      "18                 False                        False                 False   \n",
      "24                 False                        False                 False   \n",
      "\n",
      "    event_E6_HighTemp_gt24  SolarRadWm2_015m  TempC_002m  TempC_035m  \\\n",
      "0                    False               NaN         NaN         NaN   \n",
      "6                    False               NaN         NaN         NaN   \n",
      "12                   False               NaN         NaN         NaN   \n",
      "18                   False               NaN         NaN         NaN   \n",
      "24                   False               NaN         NaN         NaN   \n",
      "\n",
      "    TempC_060m  RelHum_002m  AbsHum_002m  WSpdMph_035m  WSpdMph_060m  \\\n",
      "0          NaN          NaN          NaN           NaN           NaN   \n",
      "6          NaN          NaN          NaN           NaN           NaN   \n",
      "12         NaN          NaN          NaN           NaN           NaN   \n",
      "18         NaN          NaN          NaN           NaN           NaN   \n",
      "24         NaN          NaN          NaN           NaN           NaN   \n",
      "\n",
      "    PkWSpdMph_035m  PkWSpdMph_060m  VSSpdMph_060m  SolarRadWm2_002m  \\\n",
      "0              NaN             NaN            NaN               NaN   \n",
      "6              NaN             NaN            NaN               NaN   \n",
      "12             NaN             NaN            NaN               NaN   \n",
      "18             NaN             NaN            NaN               NaN   \n",
      "24             NaN             NaN            NaN               NaN   \n",
      "\n",
      "    BarPresMb_002m  Sigma_035m  Sigma_060m  SigPhi_060m  WDir_035m  WDir_060m  \\\n",
      "0              NaN         NaN         NaN          NaN        NaN        NaN   \n",
      "6              NaN         NaN         NaN          NaN        NaN        NaN   \n",
      "12             NaN         NaN         NaN          NaN        NaN        NaN   \n",
      "18             NaN         NaN         NaN          NaN        NaN        NaN   \n",
      "24             NaN         NaN         NaN          NaN        NaN        NaN   \n",
      "\n",
      "    PrecipIn_002m  TempC_010m  RelHum_010m  AbsHum_010m  WSpdMph_010m  \\\n",
      "0             NaN         NaN          NaN          NaN           NaN   \n",
      "6             NaN         NaN          NaN          NaN           NaN   \n",
      "12            NaN         NaN          NaN          NaN           NaN   \n",
      "18            NaN         NaN          NaN          NaN           NaN   \n",
      "24            NaN         NaN          NaN          NaN           NaN   \n",
      "\n",
      "    PkWSpdMph_010m  VSSpdMph_010m  SolarRadWm2_010m  BarPresMb_010m  \\\n",
      "0              NaN            NaN               NaN             NaN   \n",
      "6              NaN            NaN               NaN             NaN   \n",
      "12             NaN            NaN               NaN             NaN   \n",
      "18             NaN            NaN               NaN             NaN   \n",
      "24             NaN            NaN               NaN             NaN   \n",
      "\n",
      "    Sigma_010m  SigPhi_010m  WDir_010m  PrecipIn_010m  TempC_025m  \\\n",
      "0          NaN          NaN        NaN            NaN         NaN   \n",
      "6          NaN          NaN        NaN            NaN         NaN   \n",
      "12         NaN          NaN        NaN            NaN         NaN   \n",
      "18         NaN          NaN        NaN            NaN         NaN   \n",
      "24         NaN          NaN        NaN            NaN         NaN   \n",
      "\n",
      "    WSpdMph_025m  PkWSpdMph_025m  VSSpdMph_025m  Sigma_025m  SigPhi_025m  \\\n",
      "0            NaN             NaN            NaN         NaN          NaN   \n",
      "6            NaN             NaN            NaN         NaN          NaN   \n",
      "12           NaN             NaN            NaN         NaN          NaN   \n",
      "18           NaN             NaN            NaN         NaN          NaN   \n",
      "24           NaN             NaN            NaN         NaN          NaN   \n",
      "\n",
      "    WDir_025m  TempC_033m  WSpdMph_033m  PkWSpdMph_033m  VSSpdMph_033m  \\\n",
      "0         NaN         NaN           NaN             NaN            NaN   \n",
      "6         NaN         NaN           NaN             NaN            NaN   \n",
      "12        NaN         NaN           NaN             NaN            NaN   \n",
      "18        NaN         NaN           NaN             NaN            NaN   \n",
      "24        NaN         NaN           NaN             NaN            NaN   \n",
      "\n",
      "    Sigma_033m  SigPhi_033m  WDir_033m  true_event_count  \n",
      "0          NaN          NaN        NaN                 0  \n",
      "6          NaN          NaN        NaN                 0  \n",
      "12         NaN          NaN        NaN                 0  \n",
      "18         NaN          NaN        NaN                 0  \n",
      "24         NaN          NaN        NaN                 0  \n"
     ]
    }
   ],
   "source": [
    "# Check all unique tower types\n",
    "print(\"Unique tower types:\", df['tower'].unique())\n",
    "\n",
    "# Split into separate DataFrames per tower\n",
    "tower_dfs = {tower: df[df['tower'] == tower].copy() for tower in df['tower'].unique()}\n",
    "\n",
    "# Example: Access one tower's dataset\n",
    "print(\"\\nExample  TOWA DataFrame:\")\n",
    "print(tower_dfs['TOWA'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa032404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 010% nulls =====\n",
      "Tower TOWA: 24 columns  ['tower', 'timestamp', 'TempC_015m', 'TempC_030m', 'RelHum_015m', 'AbsHum_015m', 'WSpdMph_015m', 'PkWSpdMph_015m', 'PkWSpdMph_030m', 'VSSpdMph_015m', 'VSSpdMph_030m', 'BarPresMb_015m', 'Sigma_015m', 'Sigma_030m', 'SigPhi_015m', 'SigPhi_030m', 'WDir_015m', 'WDir_030m', 'PrecipIn_015m', 'event_E3_LowTemp_lt0', 'event_E4_HighWind_Peak_gt25', 'event_E5_LowWind_lt2', 'event_E6_HighTemp_gt24', 'true_event_count']\n",
      "Tower TOWB: 8 columns  ['tower', 'timestamp', 'BarPresMb_015m', 'event_E3_LowTemp_lt0', 'event_E4_HighWind_Peak_gt25', 'event_E5_LowWind_lt2', 'event_E6_HighTemp_gt24', 'true_event_count']\n",
      "Tower TOWD: 30 columns  ['tower', 'timestamp', 'TempC_015m', 'RelHum_015m', 'AbsHum_015m', 'BarPresMb_015m', 'Sigma_015m', 'SigPhi_015m', 'event_E3_LowTemp_lt0', 'event_E4_HighWind_Peak_gt25', 'event_E5_LowWind_lt2', 'event_E6_HighTemp_gt24', 'TempC_002m', 'TempC_035m', 'TempC_060m', 'RelHum_002m', 'AbsHum_002m', 'WSpdMph_035m', 'WSpdMph_060m', 'PkWSpdMph_035m', 'PkWSpdMph_060m', 'SolarRadWm2_002m', 'BarPresMb_002m', 'Sigma_035m', 'Sigma_060m', 'SigPhi_060m', 'WDir_035m', 'WDir_060m', 'PrecipIn_002m', 'true_event_count']\n",
      "Tower TOWF: 7 columns  ['tower', 'timestamp', 'event_E3_LowTemp_lt0', 'event_E4_HighWind_Peak_gt25', 'event_E5_LowWind_lt2', 'event_E6_HighTemp_gt24', 'true_event_count']\n",
      "Tower TOWS: 14 columns  ['tower', 'timestamp', 'event_E3_LowTemp_lt0', 'event_E4_HighWind_Peak_gt25', 'event_E5_LowWind_lt2', 'event_E6_HighTemp_gt24', 'TempC_025m', 'WSpdMph_025m', 'PkWSpdMph_025m', 'VSSpdMph_025m', 'Sigma_025m', 'SigPhi_025m', 'WDir_025m', 'true_event_count']\n",
      "Tower TOWY: 25 columns  ['tower', 'timestamp', 'TempC_015m', 'RelHum_015m', 'WSpdMph_015m', 'PkWSpdMph_015m', 'VSSpdMph_015m', 'BarPresMb_015m', 'Sigma_015m', 'SigPhi_015m', 'WDir_015m', 'PrecipIn_015m', 'event_E3_LowTemp_lt0', 'event_E4_HighWind_Peak_gt25', 'event_E5_LowWind_lt2', 'event_E6_HighTemp_gt24', 'SolarRadWm2_015m', 'TempC_033m', 'WSpdMph_033m', 'PkWSpdMph_033m', 'VSSpdMph_033m', 'Sigma_033m', 'SigPhi_033m', 'WDir_033m', 'true_event_count']\n",
      "\n",
      "===== 1020% nulls =====\n",
      "Tower TOWA: 1 columns  ['WSpdMph_030m']\n",
      "Tower TOWB: 11 columns  ['TempC_015m', 'TempC_030m', 'WSpdMph_015m', 'WSpdMph_030m', 'PkWSpdMph_015m', 'PkWSpdMph_030m', 'Sigma_015m', 'Sigma_030m', 'WDir_015m', 'WDir_030m', 'PrecipIn_015m']\n",
      "Tower TOWD: 5 columns  ['WSpdMph_015m', 'PkWSpdMph_015m', 'VSSpdMph_015m', 'WDir_015m', 'VSSpdMph_060m']\n",
      "Tower TOWF: 9 columns  ['TempC_010m', 'RelHum_010m', 'AbsHum_010m', 'PkWSpdMph_010m', 'SolarRadWm2_010m', 'Sigma_010m', 'SigPhi_010m', 'WDir_010m', 'PrecipIn_010m']\n",
      "\n",
      "===== 2030% nulls =====\n",
      "Tower TOWB: 4 columns  ['VSSpdMph_015m', 'VSSpdMph_030m', 'SigPhi_015m', 'SigPhi_030m']\n",
      "Tower TOWF: 1 columns  ['BarPresMb_010m']\n",
      "\n",
      "===== 3040% nulls =====\n",
      "Tower TOWB: 1 columns  ['RelHum_015m']\n",
      "Tower TOWF: 1 columns  ['WSpdMph_010m']\n",
      "\n",
      "===== 4050% nulls =====\n",
      "Tower TOWF: 1 columns  ['VSSpdMph_010m']\n",
      "\n",
      "===== 5060% nulls =====\n",
      "\n",
      "===== 6070% nulls =====\n",
      "\n",
      "===== 7080% nulls =====\n",
      "\n",
      "===== 8090% nulls =====\n",
      "\n",
      "===== 90100% nulls =====\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ensure timestamp is datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Compute % of nulls per column and tower\n",
    "null_percentage = df.groupby('tower').apply(lambda x: x.isnull().mean() * 100).round(2)\n",
    "\n",
    "# Define non-overlapping ranges: 010%, 1020%, ..., 90100%\n",
    "bins = np.arange(0, 110, 10)  # 0,10,20,...,100\n",
    "range_labels = [f\"{bins[i]}{bins[i+1]}% nulls\" for i in range(len(bins)-1)]\n",
    "\n",
    "# Store results in dictionary\n",
    "ranges = {label: [] for label in range_labels}\n",
    "\n",
    "for tower in null_percentage.index:\n",
    "    tower_data = null_percentage.loc[tower]\n",
    "    for i in range(len(bins)-1):\n",
    "        low, high = bins[i], bins[i+1]\n",
    "        cols = list(tower_data[(tower_data >= low) & (tower_data < high)].index)\n",
    "        ranges[range_labels[i]].append((tower, cols))\n",
    "\n",
    "# Print summary\n",
    "for category, values in ranges.items():\n",
    "    print(f\"\\n===== {category} =====\")\n",
    "    for tower, cols in values:\n",
    "        if len(cols) > 0:\n",
    "            print(f\"Tower {tower}: {len(cols)} columns  {cols}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0beed293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dfs_below_threshold(df, ranges, threshold=100):\n",
    "    \"\"\"\n",
    "    Filter all towers, keeping columns whose null % is below a threshold.\n",
    "    Always keeps 'tower', 'timestamp' and 'true_event_count'.\n",
    "    \"\"\"\n",
    "    filtered_dfs = {}\n",
    "    \n",
    "    # Find all ranges below threshold\n",
    "    selected_ranges = [r for r in ranges.keys() if int(r.split(\"\")[1].replace(\"% nulls\",\"\")) <= threshold]\n",
    "    \n",
    "    for tower in df['tower'].unique():\n",
    "        cols_to_keep = ['tower', 'timestamp']  # <-- keep true_event_count\n",
    "        \n",
    "        # Collect columns from all selected ranges\n",
    "        for r in selected_ranges:\n",
    "            for t, cols in ranges[r]:\n",
    "                if t == tower:\n",
    "                    cols_to_keep.extend(cols)\n",
    "        \n",
    "        # Remove duplicates (some columns may appear in multiple ranges)\n",
    "        cols_to_keep = list(dict.fromkeys(cols_to_keep))\n",
    "        \n",
    "        # Guard: keep only columns that actually exist in the dataframe\n",
    "        cols_to_keep = [c for c in cols_to_keep if c in df.columns]\n",
    "        \n",
    "        filtered_dfs[tower] = df[df['tower'] == tower][cols_to_keep].copy()\n",
    "        filtered_dfs[tower] = filtered_dfs[tower].drop(\"true_event_count\", axis=1)\n",
    "    \n",
    "    return filtered_dfs\n",
    "\n",
    "filtered_dfs = filter_dfs_below_threshold(df, ranges, threshold=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9c8b896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TOWA': ['tower',\n",
       "  'timestamp',\n",
       "  'TempC_015m',\n",
       "  'TempC_030m',\n",
       "  'RelHum_015m',\n",
       "  'AbsHum_015m',\n",
       "  'WSpdMph_015m',\n",
       "  'PkWSpdMph_015m',\n",
       "  'PkWSpdMph_030m',\n",
       "  'VSSpdMph_015m',\n",
       "  'VSSpdMph_030m',\n",
       "  'BarPresMb_015m',\n",
       "  'Sigma_015m',\n",
       "  'Sigma_030m',\n",
       "  'SigPhi_015m',\n",
       "  'SigPhi_030m',\n",
       "  'WDir_015m',\n",
       "  'WDir_030m',\n",
       "  'PrecipIn_015m',\n",
       "  'event_E3_LowTemp_lt0',\n",
       "  'event_E4_HighWind_Peak_gt25',\n",
       "  'event_E5_LowWind_lt2',\n",
       "  'event_E6_HighTemp_gt24',\n",
       "  'WSpdMph_030m'],\n",
       " 'TOWB': ['tower',\n",
       "  'timestamp',\n",
       "  'BarPresMb_015m',\n",
       "  'event_E3_LowTemp_lt0',\n",
       "  'event_E4_HighWind_Peak_gt25',\n",
       "  'event_E5_LowWind_lt2',\n",
       "  'event_E6_HighTemp_gt24',\n",
       "  'TempC_015m',\n",
       "  'TempC_030m',\n",
       "  'WSpdMph_015m',\n",
       "  'WSpdMph_030m',\n",
       "  'PkWSpdMph_015m',\n",
       "  'PkWSpdMph_030m',\n",
       "  'Sigma_015m',\n",
       "  'Sigma_030m',\n",
       "  'WDir_015m',\n",
       "  'WDir_030m',\n",
       "  'PrecipIn_015m',\n",
       "  'VSSpdMph_015m',\n",
       "  'VSSpdMph_030m',\n",
       "  'SigPhi_015m',\n",
       "  'SigPhi_030m',\n",
       "  'RelHum_015m'],\n",
       " 'TOWD': ['tower',\n",
       "  'timestamp',\n",
       "  'TempC_015m',\n",
       "  'RelHum_015m',\n",
       "  'AbsHum_015m',\n",
       "  'BarPresMb_015m',\n",
       "  'Sigma_015m',\n",
       "  'SigPhi_015m',\n",
       "  'event_E3_LowTemp_lt0',\n",
       "  'event_E4_HighWind_Peak_gt25',\n",
       "  'event_E5_LowWind_lt2',\n",
       "  'event_E6_HighTemp_gt24',\n",
       "  'TempC_002m',\n",
       "  'TempC_035m',\n",
       "  'TempC_060m',\n",
       "  'RelHum_002m',\n",
       "  'AbsHum_002m',\n",
       "  'WSpdMph_035m',\n",
       "  'WSpdMph_060m',\n",
       "  'PkWSpdMph_035m',\n",
       "  'PkWSpdMph_060m',\n",
       "  'SolarRadWm2_002m',\n",
       "  'BarPresMb_002m',\n",
       "  'Sigma_035m',\n",
       "  'Sigma_060m',\n",
       "  'SigPhi_060m',\n",
       "  'WDir_035m',\n",
       "  'WDir_060m',\n",
       "  'PrecipIn_002m',\n",
       "  'WSpdMph_015m',\n",
       "  'PkWSpdMph_015m',\n",
       "  'VSSpdMph_015m',\n",
       "  'WDir_015m',\n",
       "  'VSSpdMph_060m'],\n",
       " 'TOWF': ['tower',\n",
       "  'timestamp',\n",
       "  'event_E3_LowTemp_lt0',\n",
       "  'event_E4_HighWind_Peak_gt25',\n",
       "  'event_E5_LowWind_lt2',\n",
       "  'event_E6_HighTemp_gt24',\n",
       "  'TempC_010m',\n",
       "  'RelHum_010m',\n",
       "  'AbsHum_010m',\n",
       "  'PkWSpdMph_010m',\n",
       "  'SolarRadWm2_010m',\n",
       "  'Sigma_010m',\n",
       "  'SigPhi_010m',\n",
       "  'WDir_010m',\n",
       "  'PrecipIn_010m',\n",
       "  'BarPresMb_010m',\n",
       "  'WSpdMph_010m',\n",
       "  'VSSpdMph_010m'],\n",
       " 'TOWS': ['tower',\n",
       "  'timestamp',\n",
       "  'event_E3_LowTemp_lt0',\n",
       "  'event_E4_HighWind_Peak_gt25',\n",
       "  'event_E5_LowWind_lt2',\n",
       "  'event_E6_HighTemp_gt24',\n",
       "  'TempC_025m',\n",
       "  'WSpdMph_025m',\n",
       "  'PkWSpdMph_025m',\n",
       "  'VSSpdMph_025m',\n",
       "  'Sigma_025m',\n",
       "  'SigPhi_025m',\n",
       "  'WDir_025m'],\n",
       " 'TOWY': ['tower',\n",
       "  'timestamp',\n",
       "  'TempC_015m',\n",
       "  'RelHum_015m',\n",
       "  'WSpdMph_015m',\n",
       "  'PkWSpdMph_015m',\n",
       "  'VSSpdMph_015m',\n",
       "  'BarPresMb_015m',\n",
       "  'Sigma_015m',\n",
       "  'SigPhi_015m',\n",
       "  'WDir_015m',\n",
       "  'PrecipIn_015m',\n",
       "  'event_E3_LowTemp_lt0',\n",
       "  'event_E4_HighWind_Peak_gt25',\n",
       "  'event_E5_LowWind_lt2',\n",
       "  'event_E6_HighTemp_gt24',\n",
       "  'SolarRadWm2_015m',\n",
       "  'TempC_033m',\n",
       "  'WSpdMph_033m',\n",
       "  'PkWSpdMph_033m',\n",
       "  'VSSpdMph_033m',\n",
       "  'Sigma_033m',\n",
       "  'SigPhi_033m',\n",
       "  'WDir_033m']}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{tower: list(df.columns) for tower, df in filtered_dfs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b92f1d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily disable truncation\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.width', None)        # No width limit\n",
    "pd.set_option('display.max_colwidth', None) # Full column names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b53be29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tower</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>TempC_015m</th>\n",
       "      <th>TempC_030m</th>\n",
       "      <th>RelHum_015m</th>\n",
       "      <th>AbsHum_015m</th>\n",
       "      <th>WSpdMph_015m</th>\n",
       "      <th>PkWSpdMph_015m</th>\n",
       "      <th>PkWSpdMph_030m</th>\n",
       "      <th>VSSpdMph_015m</th>\n",
       "      <th>VSSpdMph_030m</th>\n",
       "      <th>BarPresMb_015m</th>\n",
       "      <th>Sigma_015m</th>\n",
       "      <th>Sigma_030m</th>\n",
       "      <th>SigPhi_015m</th>\n",
       "      <th>SigPhi_030m</th>\n",
       "      <th>WDir_015m</th>\n",
       "      <th>WDir_030m</th>\n",
       "      <th>PrecipIn_015m</th>\n",
       "      <th>event_E3_LowTemp_lt0</th>\n",
       "      <th>event_E4_HighWind_Peak_gt25</th>\n",
       "      <th>event_E5_LowWind_lt2</th>\n",
       "      <th>event_E6_HighTemp_gt24</th>\n",
       "      <th>WSpdMph_030m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TOWA</td>\n",
       "      <td>2017-01-01 05:00:00+00:00</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>97.4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>985.3</td>\n",
       "      <td>26.5</td>\n",
       "      <td>15.5</td>\n",
       "      <td>18.9</td>\n",
       "      <td>12.6</td>\n",
       "      <td>268.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>0.015748</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TOWA</td>\n",
       "      <td>2017-01-01 05:15:00+00:00</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>97.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>6.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>985.3</td>\n",
       "      <td>19.3</td>\n",
       "      <td>13.9</td>\n",
       "      <td>14.3</td>\n",
       "      <td>9.8</td>\n",
       "      <td>252.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.011811</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TOWA</td>\n",
       "      <td>2017-01-01 05:30:00+00:00</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>97.4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>985.2</td>\n",
       "      <td>25.3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>11.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>0.011811</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TOWA</td>\n",
       "      <td>2017-01-01 05:45:00+00:00</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>97.4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.8</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>985.0</td>\n",
       "      <td>29.4</td>\n",
       "      <td>16.6</td>\n",
       "      <td>14.4</td>\n",
       "      <td>8.3</td>\n",
       "      <td>268.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>TOWA</td>\n",
       "      <td>2017-01-01 06:00:00+00:00</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>97.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>985.1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>14.9</td>\n",
       "      <td>10.8</td>\n",
       "      <td>268.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261692</th>\n",
       "      <td>TOWA</td>\n",
       "      <td>2023-01-01 03:30:00+00:00</td>\n",
       "      <td>10.1</td>\n",
       "      <td>12.3</td>\n",
       "      <td>98.5</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>984.4</td>\n",
       "      <td>78.6</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>3.4</td>\n",
       "      <td>120.7</td>\n",
       "      <td>248.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261698</th>\n",
       "      <td>TOWA</td>\n",
       "      <td>2023-01-01 03:45:00+00:00</td>\n",
       "      <td>10.2</td>\n",
       "      <td>11.8</td>\n",
       "      <td>98.6</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>984.4</td>\n",
       "      <td>66.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>273.6</td>\n",
       "      <td>263.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261704</th>\n",
       "      <td>TOWA</td>\n",
       "      <td>2023-01-01 04:00:00+00:00</td>\n",
       "      <td>10.4</td>\n",
       "      <td>11.7</td>\n",
       "      <td>98.6</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>984.5</td>\n",
       "      <td>45.9</td>\n",
       "      <td>15.7</td>\n",
       "      <td>12.4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>253.0</td>\n",
       "      <td>259.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261710</th>\n",
       "      <td>TOWA</td>\n",
       "      <td>2023-01-01 04:15:00+00:00</td>\n",
       "      <td>10.2</td>\n",
       "      <td>11.7</td>\n",
       "      <td>98.6</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>984.5</td>\n",
       "      <td>91.1</td>\n",
       "      <td>12.3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>294.1</td>\n",
       "      <td>268.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261716</th>\n",
       "      <td>TOWA</td>\n",
       "      <td>2023-01-01 04:30:00+00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>98.6</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>984.6</td>\n",
       "      <td>46.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>206.3</td>\n",
       "      <td>284.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210287 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tower                 timestamp  TempC_015m  TempC_030m  RelHum_015m  \\\n",
       "0        TOWA 2017-01-01 05:00:00+00:00         3.6         3.6         97.4   \n",
       "6        TOWA 2017-01-01 05:15:00+00:00         3.6         3.6         97.3   \n",
       "12       TOWA 2017-01-01 05:30:00+00:00         3.6         3.7         97.4   \n",
       "18       TOWA 2017-01-01 05:45:00+00:00         3.7         3.7         97.4   \n",
       "24       TOWA 2017-01-01 06:00:00+00:00         3.8         3.8         97.3   \n",
       "...       ...                       ...         ...         ...          ...   \n",
       "1261692  TOWA 2023-01-01 03:30:00+00:00        10.1        12.3         98.5   \n",
       "1261698  TOWA 2023-01-01 03:45:00+00:00        10.2        11.8         98.6   \n",
       "1261704  TOWA 2023-01-01 04:00:00+00:00        10.4        11.7         98.6   \n",
       "1261710  TOWA 2023-01-01 04:15:00+00:00        10.2        11.7         98.6   \n",
       "1261716  TOWA 2023-01-01 04:30:00+00:00        10.0        12.2         98.6   \n",
       "\n",
       "         AbsHum_015m  WSpdMph_015m  PkWSpdMph_015m  PkWSpdMph_030m  \\\n",
       "0                6.0           2.2             5.9            10.2   \n",
       "6                6.0           2.4             6.7             7.7   \n",
       "12               6.0           2.8             6.0             6.8   \n",
       "18               6.0           2.5             5.1             6.8   \n",
       "24               6.0           2.2             4.2             6.3   \n",
       "...              ...           ...             ...             ...   \n",
       "1261692          9.2           0.4             NaN             NaN   \n",
       "1261698          9.3           0.2             NaN             NaN   \n",
       "1261704          9.4           0.7             NaN             NaN   \n",
       "1261710          9.3           0.4             NaN             NaN   \n",
       "1261716          9.2           0.4             NaN             NaN   \n",
       "\n",
       "         VSSpdMph_015m  VSSpdMph_030m  BarPresMb_015m  Sigma_015m  Sigma_030m  \\\n",
       "0                  0.0      -0.100000           985.3        26.5        15.5   \n",
       "6                  0.0      -0.100000           985.3        19.3        13.9   \n",
       "12                -0.2       0.000064           985.2        25.3        15.0   \n",
       "18                -0.2      -0.100000           985.0        29.4        16.6   \n",
       "24                 0.0       0.100000           985.1        25.0        13.1   \n",
       "...                ...            ...             ...         ...         ...   \n",
       "1261692            0.0            NaN           984.4        78.6        11.0   \n",
       "1261698            0.0            NaN           984.4        66.5        15.0   \n",
       "1261704            0.0            NaN           984.5        45.9        15.7   \n",
       "1261710            0.0            NaN           984.5        91.1        12.3   \n",
       "1261716            0.0            NaN           984.6        46.8         4.5   \n",
       "\n",
       "         SigPhi_015m  SigPhi_030m  WDir_015m  WDir_030m  PrecipIn_015m  \\\n",
       "0               18.9         12.6      268.0      274.0       0.015748   \n",
       "6               14.3          9.8      252.0      264.0       0.011811   \n",
       "12              13.6         11.0      255.0      260.0       0.011811   \n",
       "18              14.4          8.3      268.0      263.0       0.007874   \n",
       "24              14.9         10.8      268.0      274.0       0.007874   \n",
       "...              ...          ...        ...        ...            ...   \n",
       "1261692         12.9          3.4      120.7      248.9       0.000000   \n",
       "1261698          5.7          3.8      273.6      263.7       0.000000   \n",
       "1261704         12.4          4.8      253.0      259.9       0.000000   \n",
       "1261710         11.0          4.2      294.1      268.0       0.000000   \n",
       "1261716          9.4          3.9      206.3      284.2       0.000000   \n",
       "\n",
       "         event_E3_LowTemp_lt0  event_E4_HighWind_Peak_gt25  \\\n",
       "0                       False                        False   \n",
       "6                       False                        False   \n",
       "12                      False                        False   \n",
       "18                      False                        False   \n",
       "24                      False                        False   \n",
       "...                       ...                          ...   \n",
       "1261692                 False                        False   \n",
       "1261698                 False                        False   \n",
       "1261704                 False                        False   \n",
       "1261710                 False                        False   \n",
       "1261716                 False                        False   \n",
       "\n",
       "         event_E5_LowWind_lt2  event_E6_HighTemp_gt24  WSpdMph_030m  \n",
       "0                       False                   False           4.4  \n",
       "6                       False                   False           4.7  \n",
       "12                      False                   False           4.3  \n",
       "18                      False                   False           4.2  \n",
       "24                      False                   False           4.0  \n",
       "...                       ...                     ...           ...  \n",
       "1261692                 False                   False           2.6  \n",
       "1261698                 False                   False           2.5  \n",
       "1261704                 False                   False           3.1  \n",
       "1261710                 False                   False           2.9  \n",
       "1261716                 False                   False           3.2  \n",
       "\n",
       "[210287 rows x 24 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_dfs['TOWA']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b923491",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c861bb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MULTI-EVENT TEMPORAL FORECASTING - DEEP LEARNING\n",
      "======================================================================\n",
      "Device: cuda\n",
      "Batch size: 32\n",
      "======================================================================\n",
      "GPU 0: Allocated: 0.03GB, Reserved: 0.05GB\n",
      "\n",
      "================================================================================\n",
      "RUNNING MULTI-EVENT DEEP LEARNING EXPERIMENTS\n",
      "================================================================================\n",
      "Device: cuda\n",
      "Models: cnn, tcn\n",
      "Sequence Length: 48\n",
      "Batch Size: 32\n",
      "================================================================================\n",
      "\n",
      "======================================================================\n",
      "  TOWER: TOWA\n",
      "======================================================================\n",
      "\n",
      "    Event: event_E3_LowTemp_lt0\n",
      "       Samples: 147,466 | Events: 7,441.0 (5.05%)\n",
      "       Features: 18\n",
      "         Fold 1/5 [cnn] [tcn] \n",
      "         Fold 2/5 [cnn] [tcn] \n",
      "         Fold 3/5 [cnn] "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1217\u001b[39m\n\u001b[32m   1214\u001b[39m get_gpu_memory_info()\n\u001b[32m   1216\u001b[39m \u001b[38;5;66;03m# Run experiments\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1217\u001b[39m all_results = \u001b[43mrun_multi_event_experiments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered_dfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1220\u001b[39m \u001b[38;5;66;03m# Save results\u001b[39;00m\n\u001b[32m   1221\u001b[39m output_dir = save_all_results(all_results, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 849\u001b[39m, in \u001b[36mrun_multi_event_experiments\u001b[39m\u001b[34m(filtered_dfs, config)\u001b[39m\n\u001b[32m    845\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m       Features: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(feature_cols)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    847\u001b[39m metadata = tower_df.loc[X.index, [\u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m]].copy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tower_df.columns \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m849\u001b[39m results = \u001b[43mtrain_single_tower_event_models\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    850\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtower_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\n\u001b[32m    851\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    853\u001b[39m all_results[tower_name][event_col] = {\n\u001b[32m    854\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mresults\u001b[39m\u001b[33m'\u001b[39m: results,\n\u001b[32m    855\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mimportance\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# Deep learning models don't have feature importance\u001b[39;00m\n\u001b[32m    856\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mn_samples\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(y),\n\u001b[32m    857\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mevent_rate\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(y.mean())\n\u001b[32m    858\u001b[39m }\n\u001b[32m    860\u001b[39m \u001b[38;5;66;03m# Print summary\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 602\u001b[39m, in \u001b[36mtrain_single_tower_event_models\u001b[39m\u001b[34m(X, y, config, tower_name, event_name, metadata)\u001b[39m\n\u001b[32m    599\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m model_type \u001b[38;5;129;01min\u001b[39;00m config.MODELS_TO_TRAIN:\n\u001b[32m    600\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m, end=\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m602\u001b[39m     model, history = \u001b[43mtrain_deep_learning_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    604\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_weights\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m     \u001b[38;5;66;03m# Predict on validation set\u001b[39;00m\n\u001b[32m    608\u001b[39m     y_pred_proba = predict_with_model(model, X_val, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 473\u001b[39m, in \u001b[36mtrain_deep_learning_model\u001b[39m\u001b[34m(X_train, y_train, X_val, y_val, model_type, config, class_weights)\u001b[39m\n\u001b[32m    470\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    471\u001b[39m     weighted_loss = loss_per_sample.mean()\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m \u001b[43mweighted_loss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m optimizer.step()\n\u001b[32m    476\u001b[39m train_loss += weighted_loss.item() * \u001b[38;5;28mlen\u001b[39m(X_batch)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/ml_env2/lib/python3.11/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/ml_env2/lib/python3.11/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/ml_env2/lib/python3.11/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ==================== MULTI-EVENT TEMPORAL FORECASTING - DEEP LEARNING MODELS ====================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import (classification_report, roc_auc_score, confusion_matrix,\n",
    "                             precision_recall_curve, f1_score, precision_score, recall_score,\n",
    "                             accuracy_score, balanced_accuracy_score, matthews_corrcoef, \n",
    "                             cohen_kappa_score, average_precision_score)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pytorch_tcn import TCN  # Changed from: from tcn import TCN, tcn_full_summary\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import warnings\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import json\n",
    "from pathlib import Path\n",
    "import gc\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "def clear_gpu_memory():\n",
    "    \"\"\"Clear GPU memory cache\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "def get_gpu_memory_info():\n",
    "    \"\"\"Print current GPU memory usage\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            allocated = torch.cuda.memory_allocated(i) / 1024**3\n",
    "            reserved = torch.cuda.memory_reserved(i) / 1024**3\n",
    "            print(f\"GPU {i}: Allocated: {allocated:.2f}GB, Reserved: {reserved:.2f}GB\")\n",
    "\n",
    "\n",
    "# ==================== PYTORCH DATASET ====================\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for time series data\"\"\"\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray, sequence_length: int = 24):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X: Input features (n_samples, n_features)\n",
    "            y: Target labels (n_samples,)\n",
    "            sequence_length: Length of sequence for each sample\n",
    "        \"\"\"\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.y = torch.FloatTensor(y)\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X) - self.sequence_length + 1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Return sequence of length sequence_length\n",
    "        X_seq = self.X[idx:idx + self.sequence_length]\n",
    "        y_target = self.y[idx + self.sequence_length - 1]\n",
    "        return X_seq, y_target\n",
    "\n",
    "\n",
    "# ==================== DEEP LEARNING MODELS ====================\n",
    "\n",
    "# class TemporalBlock(nn.Module):\n",
    "#     \"\"\"A single temporal block for TCN\"\"\"\n",
    "#     def __init__(self, in_channels, out_channels, kernel_size, stride, dilation, padding, dropout):\n",
    "#         super(TemporalBlock, self).__init__()\n",
    "#         self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size,\n",
    "#                                stride=stride, padding=padding, dilation=dilation)\n",
    "#         self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "#         self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size,\n",
    "#                                stride=stride, padding=padding, dilation=dilation)\n",
    "#         self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "#         self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "#         self.downsample = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else None\n",
    "#         self.relu = nn.ReLU()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         out = self.dropout1(self.relu1(self.bn1(self.conv1(x))))\n",
    "#         out = self.dropout2(self.relu2(self.bn2(self.conv2(out))))\n",
    "#         res = x if self.downsample is None else self.downsample(x)\n",
    "#         return self.relu(out + res)\n",
    "\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    \"\"\"A single temporal block for TCN with causal convolutions\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, dilation, padding, dropout):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        self.padding = padding  # Store padding for trimming\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size,\n",
    "                               stride=stride, padding=padding, dilation=dilation)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size,\n",
    "                               stride=stride, padding=padding, dilation=dilation)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.downsample = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else None\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        # Trim to maintain causal property and original sequence length\n",
    "        out = out[:, :, :-self.padding] if self.padding > 0 else out\n",
    "        out = self.dropout1(self.relu1(self.bn1(out)))\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = out[:, :, :-self.padding] if self.padding > 0 else out\n",
    "        out = self.dropout2(self.relu2(self.bn2(out)))\n",
    "        \n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)\n",
    "\n",
    "\n",
    "\n",
    "class TCNModel(nn.Module):\n",
    "    \"\"\"Temporal Convolutional Network - Pure PyTorch Implementation\"\"\"\n",
    "    def __init__(self, input_dim: int, hidden_dim: int = 128,\n",
    "                 num_layers: int = 4, dropout: float = 0.3,\n",
    "                 kernel_size: int = 3):\n",
    "        super(TCNModel, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        num_channels = [hidden_dim] * num_layers\n",
    "        \n",
    "        for i in range(num_layers):\n",
    "            dilation = 2 ** i\n",
    "            in_channels = input_dim if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            padding = (kernel_size - 1) * dilation\n",
    "            \n",
    "            layers.append(TemporalBlock(in_channels, out_channels, kernel_size,\n",
    "                                        stride=1, dilation=dilation,\n",
    "                                        padding=padding, dropout=dropout))\n",
    "        \n",
    "        self.tcn = nn.Sequential(*layers)\n",
    "        \n",
    "        # Classification head\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, sequence_length, features)\n",
    "        # Conv1d expects: (batch, channels, sequence_length)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        tcn_out = self.tcn(x)\n",
    "        \n",
    "        # Take last timestep output\n",
    "        last_output = tcn_out[:, :, -1]\n",
    "        \n",
    "        output = self.fc(last_output)\n",
    "        return output.squeeze(-1)\n",
    "\n",
    "\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    \"\"\"1D Convolutional Neural Network for time series classification\"\"\"\n",
    "    def __init__(self, input_dim: int, hidden_dim: int = 128,\n",
    "                 num_layers: int = 3, dropout: float = 0.3,\n",
    "                 kernel_size: int = 3):\n",
    "        super(CNNModel, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Build convolutional layers\n",
    "        layers = []\n",
    "        in_channels = input_dim\n",
    "        \n",
    "        for i in range(num_layers):\n",
    "            out_channels = hidden_dim * (2 ** min(i, 2))  # 128, 256, 512\n",
    "            layers.extend([\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size, padding=kernel_size//2),\n",
    "                nn.BatchNorm1d(out_channels),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.MaxPool1d(kernel_size=2, stride=1, padding=1)\n",
    "            ])\n",
    "            in_channels = out_channels\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(*layers)\n",
    "        \n",
    "        # Global average pooling + FC layers\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_channels, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, sequence_length, features)\n",
    "        # Conv1d expects: (batch, channels, sequence_length)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        x = self.conv_layers(x)\n",
    "        x = self.global_pool(x).squeeze(-1)\n",
    "        output = self.fc(x)\n",
    "        return output.squeeze(-1)\n",
    "\n",
    "\n",
    "# # ==================== CONFIGURATION ====================\n",
    "# class DeepLearningConfig:\n",
    "#     \"\"\"Configuration for deep learning models\"\"\"\n",
    "\n",
    "#     os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "#     DEVICE = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    \n",
    "#     # ==================== FORECASTING HORIZON ====================\n",
    "#     FORECAST_HORIZONS = {\n",
    "#         '15min': 1, '30min': 2, '1hour': 4, '3hours': 12,\n",
    "#         '6hours': 24, '12hours': 48, '24hours': 96,\n",
    "#     }\n",
    "#     SELECTED_HORIZON = '6hours'\n",
    "    \n",
    "#     # ==================== TARGET EVENTS ====================\n",
    "#     TARGET_EVENTS = [\n",
    "#         'event_E3_LowTemp_lt0',\n",
    "#         'event_E4_HighWind_Peak_gt25',\n",
    "#         'event_E5_LowWind_lt2',\n",
    "#         'event_E6_HighTemp_gt24'\n",
    "#     ]\n",
    "    \n",
    "#     # ==================== TEMPORAL FEATURES ====================\n",
    "#     LAG_CONFIGS = {\n",
    "#         'short': [1, 2, 4, 8],\n",
    "#         'medium': [1, 2, 4, 8, 16, 24],\n",
    "#         'long': [1, 4, 8, 16, 24, 48, 96],\n",
    "#     }\n",
    "#     SELECTED_LAG_CONFIG = 'medium'\n",
    "#     ROLLING_WINDOWS = [4, 12, 24, 96]\n",
    "    \n",
    "#     # ==================== MODEL PARAMETERS ====================\n",
    "#     N_SPLITS = 5\n",
    "#     DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#     USE_CLASS_WEIGHTS = True\n",
    "#     MODELS_TO_TRAIN = ['cnn', 'tcn']  # Now includes CNN and TCN\n",
    "    \n",
    "    \n",
    "#     # ==================== DEEP LEARNING HYPERPARAMETERS ====================\n",
    "#     SEQUENCE_LENGTH = 24\n",
    "#     BATCH_SIZE = 16\n",
    "#     LEARNING_RATE = 0.001\n",
    "#     NUM_EPOCHS = 100\n",
    "#     EARLY_STOPPING_PATIENCE = 15\n",
    "    \n",
    "#     # Model-specific parameters\n",
    "#     CNN_PARAMS = {\n",
    "#         'hidden_dim': 128,\n",
    "#         'num_layers': 3,\n",
    "#         'dropout': 0.3,\n",
    "#         'kernel_size': 3\n",
    "#     }\n",
    "    \n",
    "#     TCN_PARAMS = {\n",
    "#         'hidden_dim': 128,\n",
    "#         'num_layers': 4,\n",
    "#         'dropout': 0.3,\n",
    "#         'kernel_size': 3\n",
    "#     }\n",
    "    \n",
    "#     # ==================== EVALUATION METRICS ====================\n",
    "#     CLASSIFICATION_METRICS = [\n",
    "#         'accuracy',\n",
    "#         'balanced_accuracy',\n",
    "#         'precision',\n",
    "#         'recall',\n",
    "#         'f1',\n",
    "#         'auc_roc',\n",
    "#         'auc_pr',\n",
    "#         'specificity',\n",
    "#         'mcc',\n",
    "#         'cohen_kappa'\n",
    "#     ]\n",
    "\n",
    "\n",
    "# ==================== CONFIGURATION ====================\n",
    "class DeepLearningConfig:\n",
    "    \"\"\"Configuration for deep learning models (CNN & TCN)\"\"\"\n",
    "\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # ==================== FORECASTING HORIZON ====================\n",
    "    FORECAST_HORIZONS = {\n",
    "        '15min': 1, '30min': 2, '1hour': 4, '3hours': 12,\n",
    "        '6hours': 24, '12hours': 48, '24hours': 96,\n",
    "    }\n",
    "    SELECTED_HORIZON = '6hours'\n",
    "    \n",
    "    # ==================== TARGET EVENTS ====================\n",
    "    TARGET_EVENTS = [\n",
    "        'event_E3_LowTemp_lt0',\n",
    "        'event_E4_HighWind_Peak_gt25',\n",
    "        'event_E5_LowWind_lt2',\n",
    "        'event_E6_HighTemp_gt24'\n",
    "    ]\n",
    "    \n",
    "    # ==================== MODEL PARAMETERS ====================\n",
    "    N_SPLITS = 5\n",
    "    USE_CLASS_WEIGHTS = True\n",
    "    MODELS_TO_TRAIN = ['cnn', 'tcn']\n",
    "    \n",
    "    # ==================== DEEP LEARNING HYPERPARAMETERS ====================\n",
    "    #  SEQUENCE_LENGTH controls temporal context (replaces manual lag features)\n",
    "    # CNN/TCN convolve over this sequence to learn temporal patterns\n",
    "    # 24 steps = 6 hours of history (at 15-min intervals)\n",
    "    # 48 steps = 12 hours of history\n",
    "    # 96 steps = 24 hours of history\n",
    "    SEQUENCE_LENGTH = 48  # Model sees 12 hours of past data as a sequence\n",
    "    \n",
    "    BATCH_SIZE = 32\n",
    "    LEARNING_RATE = 0.001\n",
    "    NUM_EPOCHS = 100\n",
    "    EARLY_STOPPING_PATIENCE = 15\n",
    "    \n",
    "    # Model-specific parameters\n",
    "    CNN_PARAMS = {\n",
    "        'hidden_dim': 128,\n",
    "        'num_layers': 3,\n",
    "        'dropout': 0.3,\n",
    "        'kernel_size': 3\n",
    "    }\n",
    "    \n",
    "    TCN_PARAMS = {\n",
    "        'hidden_dim': 128,\n",
    "        'num_layers': 4,\n",
    "        'dropout': 0.3,\n",
    "        'kernel_size': 3\n",
    "    }\n",
    "    \n",
    "    # ==================== EVALUATION METRICS ====================\n",
    "    CLASSIFICATION_METRICS = [\n",
    "        'accuracy', 'balanced_accuracy', 'precision', 'recall',\n",
    "        'f1', 'auc_roc', 'auc_pr', 'specificity', 'mcc', 'cohen_kappa'\n",
    "    ]\n",
    "\n",
    "\n",
    "# ==================== METRICS CALCULATION ====================\n",
    "def calculate_all_metrics(y_true, y_pred, y_pred_proba):\n",
    "    \"\"\"Calculate comprehensive classification metrics\"\"\"\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'balanced_accuracy': balanced_accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred, zero_division=0),\n",
    "        'recall': recall_score(y_true, y_pred, zero_division=0),\n",
    "        'f1': f1_score(y_true, y_pred, zero_division=0),\n",
    "        'auc_roc': roc_auc_score(y_true, y_pred_proba),\n",
    "        'auc_pr': average_precision_score(y_true, y_pred_proba),\n",
    "        'specificity': tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
    "        'mcc': matthews_corrcoef(y_true, y_pred),\n",
    "        'cohen_kappa': cohen_kappa_score(y_true, y_pred),\n",
    "        'true_positives': int(tp),\n",
    "        'true_negatives': int(tn),\n",
    "        'false_positives': int(fp),\n",
    "        'false_negatives': int(fn)\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "\n",
    "# ==================== MODEL CREATION ====================\n",
    "def create_model(model_type: str, input_dim: int, config: DeepLearningConfig):\n",
    "    \"\"\"Create model based on type\"\"\"\n",
    "    if model_type == 'cnn':\n",
    "        return CNNModel(input_dim, **config.CNN_PARAMS)\n",
    "    elif model_type == 'tcn':\n",
    "        return TCNModel(input_dim, **config.TCN_PARAMS)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "\n",
    "\n",
    "\n",
    "def train_deep_learning_model(X_train: np.ndarray, y_train: np.ndarray,\n",
    "                               X_val: np.ndarray, y_val: np.ndarray,\n",
    "                               model_type: str, config: DeepLearningConfig,\n",
    "                               class_weights: Optional[torch.Tensor] = None):\n",
    "    \"\"\"Train a deep learning model\"\"\"\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = TimeSeriesDataset(X_train, y_train, config.SEQUENCE_LENGTH)\n",
    "    val_dataset = TimeSeriesDataset(X_val, y_val, config.SEQUENCE_LENGTH)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config.BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    # Create model\n",
    "    input_dim = X_train.shape[1]\n",
    "    model = create_model(model_type, input_dim, config)\n",
    "    model = model.to(config.DEVICE)\n",
    "    \n",
    "    # Loss function - use reduction='none' for per-sample weighting\n",
    "    criterion = nn.BCELoss(reduction='none')\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config.LEARNING_RATE)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', \n",
    "                                                            factor=0.5, patience=5)\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(config.NUM_EPOCHS):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_sample_count = 0\n",
    "        \n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
    "            X_batch = X_batch.to(config.DEVICE)\n",
    "            y_batch = y_batch.to(config.DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            \n",
    "            # Compute loss per sample\n",
    "            loss_per_sample = criterion(outputs, y_batch)\n",
    "            \n",
    "            # Apply class weights if provided\n",
    "            if class_weights is not None:\n",
    "                # Get the weights for this batch\n",
    "                start_idx = batch_idx * config.BATCH_SIZE\n",
    "                end_idx = min(start_idx + len(X_batch), len(train_dataset))\n",
    "                batch_weights = class_weights[start_idx:end_idx].to(config.DEVICE)\n",
    "                \n",
    "                # Weight the losses\n",
    "                weighted_loss = (loss_per_sample * batch_weights).mean()\n",
    "            else:\n",
    "                weighted_loss = loss_per_sample.mean()\n",
    "            \n",
    "            weighted_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += weighted_loss.item() * len(X_batch)\n",
    "            train_sample_count += len(X_batch)\n",
    "        \n",
    "        train_loss /= train_sample_count\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_sample_count = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch = X_batch.to(config.DEVICE)\n",
    "                y_batch = y_batch.to(config.DEVICE)\n",
    "                \n",
    "                outputs = model(X_batch)\n",
    "                loss_per_sample = criterion(outputs, y_batch)\n",
    "                loss = loss_per_sample.mean()\n",
    "                \n",
    "                val_loss += loss.item() * len(X_batch)\n",
    "                val_sample_count += len(X_batch)\n",
    "        \n",
    "        val_loss /= val_sample_count\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict().copy()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        if patience_counter >= config.EARLY_STOPPING_PATIENCE:\n",
    "            break\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(best_model_state)\n",
    "    \n",
    "    return model, {'train_losses': train_losses, 'val_losses': val_losses}\n",
    "\n",
    "\n",
    "\n",
    "def predict_with_model(model, X: np.ndarray, config: DeepLearningConfig) -> np.ndarray:\n",
    "    \"\"\"Make predictions with trained model\"\"\"\n",
    "    dataset = TimeSeriesDataset(X, np.zeros(len(X)), config.SEQUENCE_LENGTH)\n",
    "    loader = DataLoader(dataset, batch_size=config.BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, _ in loader:\n",
    "            X_batch = X_batch.to(config.DEVICE)\n",
    "            outputs = model(X_batch)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "    \n",
    "    return np.array(predictions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_single_tower_event_models(X: pd.DataFrame, y: pd.Series, \n",
    "                                    config: DeepLearningConfig,\n",
    "                                    tower_name: str,\n",
    "                                    event_name: str,\n",
    "                                    metadata: pd.DataFrame = None) -> Dict:\n",
    "    \"\"\"Train deep learning models for ONE tower and ONE event\"\"\"\n",
    "    \n",
    "    tscv = TimeSeriesSplit(n_splits=config.N_SPLITS)\n",
    "    \n",
    "    # Convert to numpy\n",
    "    X_np = X.values\n",
    "    y_np = y.values\n",
    "    \n",
    "    results = {\n",
    "        'tower': tower_name,\n",
    "        'event': event_name,\n",
    "        'models': {}\n",
    "    }\n",
    "    \n",
    "    # Initialize results for each model type\n",
    "    for model_type in config.MODELS_TO_TRAIN:\n",
    "        results['models'][model_type] = {\n",
    "            'trained_models': [],\n",
    "            'fold_metadata': [],\n",
    "            'training_history': []\n",
    "        }\n",
    "        # Initialize all metrics\n",
    "        for metric in config.CLASSIFICATION_METRICS:\n",
    "            results['models'][model_type][metric] = []\n",
    "        # Initialize confusion matrix components\n",
    "        for cm_comp in ['true_positives', 'true_negatives', 'false_positives', 'false_negatives']:\n",
    "            results['models'][model_type][cm_comp] = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(tscv.split(X_np), 1):\n",
    "        print(f\"         Fold {fold}/{config.N_SPLITS}\", end=' ')\n",
    "        \n",
    "        #  Clear GPU memory before each fold\n",
    "        clear_gpu_memory()\n",
    "        \n",
    "        X_train, X_val = X_np[train_idx], X_np[val_idx]\n",
    "        y_train, y_val = y_np[train_idx], y_np[val_idx]\n",
    "        \n",
    "        # Calculate class weights\n",
    "        class_weights = None\n",
    "        if config.USE_CLASS_WEIGHTS:\n",
    "            n_samples = len(y_train)\n",
    "            n_pos = y_train.sum()\n",
    "            n_neg = n_samples - n_pos\n",
    "            \n",
    "            if n_pos > 0 and n_neg > 0:\n",
    "                weight_pos = n_samples / (2 * n_pos)\n",
    "                weight_neg = n_samples / (2 * n_neg)\n",
    "                \n",
    "                # Create weight tensor for each sample\n",
    "                weights = np.where(y_train == 1, weight_pos, weight_neg)\n",
    "                class_weights = torch.FloatTensor(weights)\n",
    "        \n",
    "        # Train each model type\n",
    "        for model_type in config.MODELS_TO_TRAIN:\n",
    "            print(f\"[{model_type}]\", end=' ')\n",
    "            \n",
    "            model, history = train_deep_learning_model(\n",
    "                X_train, y_train, X_val, y_val,\n",
    "                model_type, config, class_weights\n",
    "            )\n",
    "            \n",
    "            # Predict on validation set\n",
    "            y_pred_proba = predict_with_model(model, X_val, config)\n",
    "            \n",
    "            # Need to adjust indices for sequence length\n",
    "            valid_indices = slice(config.SEQUENCE_LENGTH - 1, len(y_val))\n",
    "            y_val_adjusted = y_val[valid_indices]\n",
    "            \n",
    "            # Optimal threshold\n",
    "            precisions, recalls, thresholds = precision_recall_curve(y_val_adjusted, y_pred_proba)\n",
    "            f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-10)\n",
    "            optimal_idx = np.argmax(f1_scores)\n",
    "            optimal_threshold = thresholds[optimal_idx] if optimal_idx < len(thresholds) else 0.5\n",
    "            \n",
    "            y_pred = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "            \n",
    "            # Calculate all metrics\n",
    "            metrics = calculate_all_metrics(y_val_adjusted, y_pred, y_pred_proba)\n",
    "            \n",
    "            # Store metrics\n",
    "            for metric_name, metric_value in metrics.items():\n",
    "                if metric_name in results['models'][model_type]:\n",
    "                    results['models'][model_type][metric_name].append(metric_value)\n",
    "            \n",
    "            #  Move model to CPU before storing to save GPU memory\n",
    "            model = model.cpu()\n",
    "            results['models'][model_type]['trained_models'].append(model)\n",
    "            results['models'][model_type]['training_history'].append(history)\n",
    "            \n",
    "            # Store fold metadata\n",
    "            if metadata is not None:\n",
    "                fold_meta = metadata.iloc[val_idx[valid_indices]].copy()\n",
    "                fold_meta['y_true'] = y_val_adjusted\n",
    "                fold_meta['y_pred_proba'] = y_pred_proba\n",
    "                fold_meta['y_pred'] = y_pred\n",
    "                fold_meta['fold'] = fold\n",
    "                fold_meta['model_type'] = model_type\n",
    "                results['models'][model_type]['fold_metadata'].append(fold_meta)\n",
    "            \n",
    "            #  Clear GPU memory after each model\n",
    "            del model\n",
    "            clear_gpu_memory()\n",
    "        \n",
    "        print()  # New line after fold\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# # ==================== FEATURE PREPARATION ====================\n",
    "# def prepare_temporal_features(df: pd.DataFrame, config: DeepLearningConfig, \n",
    "#                               target_col: str) -> Tuple[pd.DataFrame, pd.Series, List[str]]:\n",
    "#     \"\"\"Create temporal features (lags, rolling stats) for forecasting\"\"\"\n",
    "    \n",
    "#     df = df.copy()\n",
    "#     df = df.sort_index()\n",
    "    \n",
    "#     # Get numeric columns (exclude event columns, metadata, and non-numeric)\n",
    "#     numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "#     # Exclude patterns\n",
    "#     exclude_patterns = ['event_', 'tower', 'timestamp', 'date', 'year_month', \n",
    "#                        'week_of_month', 'hour_of_day', 'day_name', 'day_numeric',\n",
    "#                        'date_numeric']\n",
    "    \n",
    "#     numeric_cols = [c for c in numeric_cols \n",
    "#                    if not any(pattern in str(c) for pattern in exclude_patterns)]\n",
    "    \n",
    "#     if target_col in numeric_cols:\n",
    "#         numeric_cols.remove(target_col)\n",
    "    \n",
    "#     for col in numeric_cols:\n",
    "#         if df[col].dtype == 'bool':\n",
    "#             df[col] = df[col].astype(int)\n",
    "    \n",
    "#     feature_dfs = []\n",
    "#     feature_names = []\n",
    "    \n",
    "#     # Original features\n",
    "#     feature_dfs.append(df[numeric_cols])\n",
    "#     feature_names.extend(numeric_cols)\n",
    "    \n",
    "#     # Lag features\n",
    "#     lags = config.LAG_CONFIGS[config.SELECTED_LAG_CONFIG]\n",
    "#     for col in numeric_cols:\n",
    "#         for lag in lags:\n",
    "#             lag_col = f'{col}_lag{lag}'\n",
    "#             feature_dfs.append(df[col].shift(lag).to_frame(lag_col))\n",
    "#             feature_names.append(lag_col)\n",
    "    \n",
    "#     # Rolling window features\n",
    "#     for col in numeric_cols:\n",
    "#         for window in config.ROLLING_WINDOWS:\n",
    "#             roll_mean_col = f'{col}_roll{window}_mean'\n",
    "#             feature_dfs.append(df[col].rolling(window=window).mean().to_frame(roll_mean_col))\n",
    "#             feature_names.append(roll_mean_col)\n",
    "            \n",
    "#             roll_std_col = f'{col}_roll{window}_std'\n",
    "#             feature_dfs.append(df[col].rolling(window=window).std().to_frame(roll_std_col))\n",
    "#             feature_names.append(roll_std_col)\n",
    "    \n",
    "#     X = pd.concat(feature_dfs, axis=1)\n",
    "    \n",
    "#     horizon_steps = config.FORECAST_HORIZONS[config.SELECTED_HORIZON]\n",
    "    \n",
    "#     if df[target_col].dtype == 'object':\n",
    "#         df[target_col] = df[target_col].astype(bool).astype(int)\n",
    "#     elif df[target_col].dtype == 'bool':\n",
    "#         df[target_col] = df[target_col].astype(int)\n",
    "    \n",
    "#     y = df[target_col].shift(-horizon_steps)\n",
    "    \n",
    "#     valid_idx = X.notna().all(axis=1) & y.notna()\n",
    "#     X = X[valid_idx]\n",
    "#     y = y[valid_idx]\n",
    "    \n",
    "#     for col in X.columns:\n",
    "#         if X[col].dtype == 'object':\n",
    "#             X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "    \n",
    "#     X = X.select_dtypes(include=[np.number])\n",
    "#     feature_names = list(X.columns)\n",
    "    \n",
    "#     return X, y, feature_names\n",
    "\n",
    "\n",
    "# ==================== FEATURE PREPARATION (SEQUENCES HANDLE TEMPORAL PATTERNS) ====================\n",
    "def prepare_temporal_features(df: pd.DataFrame, config: DeepLearningConfig, \n",
    "                              target_col: str) -> Tuple[pd.DataFrame, pd.Series, List[str]]:\n",
    "    \"\"\"\n",
    "    Prepare features for CNN/TCN models.\n",
    "    \n",
    "    NO explicit lag columns or rolling window columns needed!\n",
    "    The TimeSeriesDataset creates sequences of length SEQUENCE_LENGTH,\n",
    "    and CNN/TCN convolve over these sequences to learn temporal patterns.\n",
    "    \n",
    "    For CNN: Convolutions slide over the time dimension\n",
    "    For TCN: Dilated causal convolutions capture long-range dependencies\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.copy()\n",
    "    df = df.sort_index()\n",
    "    \n",
    "    # Get numeric columns (exclude event columns, metadata, and non-numeric)\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    # Exclude patterns\n",
    "    exclude_patterns = ['event_', 'tower', 'timestamp', 'date', 'year_month', \n",
    "                       'week_of_month', 'hour_of_day', 'day_name', 'day_numeric',\n",
    "                       'date_numeric']\n",
    "    \n",
    "    numeric_cols = [c for c in numeric_cols \n",
    "                   if not any(pattern in str(c) for pattern in exclude_patterns)]\n",
    "    \n",
    "    if target_col in numeric_cols:\n",
    "        numeric_cols.remove(target_col)\n",
    "    \n",
    "    # Convert boolean columns to int\n",
    "    for col in numeric_cols:\n",
    "        if df[col].dtype == 'bool':\n",
    "            df[col] = df[col].astype(int)\n",
    "    \n",
    "    #  Use ONLY original features - NO lag columns, NO rolling columns\n",
    "    # The SEQUENCE_LENGTH in TimeSeriesDataset handles temporal context:\n",
    "    # - CNN convolves over (batch, features, sequence_length) \n",
    "    # - TCN uses dilated convolutions for exponentially large receptive fields\n",
    "    X = df[numeric_cols].copy()\n",
    "    feature_names = list(numeric_cols)\n",
    "    \n",
    "    # Create target with forecast horizon shift\n",
    "    horizon_steps = config.FORECAST_HORIZONS[config.SELECTED_HORIZON]\n",
    "    \n",
    "    if df[target_col].dtype == 'object':\n",
    "        df[target_col] = df[target_col].astype(bool).astype(int)\n",
    "    elif df[target_col].dtype == 'bool':\n",
    "        df[target_col] = df[target_col].astype(int)\n",
    "    \n",
    "    y = df[target_col].shift(-horizon_steps)\n",
    "    \n",
    "    # Remove rows with NaN values\n",
    "    valid_idx = X.notna().all(axis=1) & y.notna()\n",
    "    X = X[valid_idx]\n",
    "    y = y[valid_idx]\n",
    "    \n",
    "    # Ensure all columns are numeric\n",
    "    for col in X.columns:\n",
    "        if X[col].dtype == 'object':\n",
    "            X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "    \n",
    "    X = X.select_dtypes(include=[np.number])\n",
    "    feature_names = list(X.columns)\n",
    "    \n",
    "    return X, y, feature_names\n",
    "\n",
    "# ==================== RUN EXPERIMENTS ====================\n",
    "def run_multi_event_experiments(filtered_dfs: Dict[str, pd.DataFrame], \n",
    "                                config: DeepLearningConfig) -> Dict:\n",
    "    \"\"\"Run experiments for all towers and all events\"\"\"\n",
    "    \n",
    "    all_results = {}\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RUNNING MULTI-EVENT DEEP LEARNING EXPERIMENTS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Device: {config.DEVICE}\")\n",
    "    print(f\"Models: {', '.join(config.MODELS_TO_TRAIN)}\")\n",
    "    print(f\"Sequence Length: {config.SEQUENCE_LENGTH}\")\n",
    "    print(f\"Batch Size: {config.BATCH_SIZE}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for tower_name, tower_df in filtered_dfs.items():\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"  TOWER: {tower_name}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        all_results[tower_name] = {}\n",
    "        \n",
    "        for event_col in config.TARGET_EVENTS:\n",
    "            \n",
    "            if event_col not in tower_df.columns:\n",
    "                print(f\"     {event_col} not found in {tower_name}, skipping...\")\n",
    "                all_results[tower_name][event_col] = {'error': 'Event column not found'}\n",
    "                continue\n",
    "            \n",
    "            print(f\"\\n    Event: {event_col}\")\n",
    "            \n",
    "            try:\n",
    "                X, y, feature_cols = prepare_temporal_features(tower_df, config, event_col)\n",
    "                \n",
    "                if len(y) < 100:\n",
    "                    print(f\"        Insufficient data ({len(y)} samples), skipping...\")\n",
    "                    all_results[tower_name][event_col] = {'error': 'Insufficient data'}\n",
    "                    continue\n",
    "                \n",
    "                if y.sum() < 10:\n",
    "                    print(f\"        Too few positive events ({y.sum()}), skipping...\")\n",
    "                    all_results[tower_name][event_col] = {'error': 'Too few positive events'}\n",
    "                    continue\n",
    "                \n",
    "                print(f\"       Samples: {len(y):,} | Events: {y.sum():,} ({y.mean()*100:.2f}%)\")\n",
    "                print(f\"       Features: {len(feature_cols)}\")\n",
    "                \n",
    "                metadata = tower_df.loc[X.index, ['timestamp']].copy() if 'timestamp' in tower_df.columns else None\n",
    "                \n",
    "                results = train_single_tower_event_models(\n",
    "                    X, y, config, tower_name, event_col, metadata\n",
    "                )\n",
    "                \n",
    "                all_results[tower_name][event_col] = {\n",
    "                    'results': results,\n",
    "                    'importance': None,  # Deep learning models don't have feature importance\n",
    "                    'n_samples': len(y),\n",
    "                    'event_rate': float(y.mean())\n",
    "                }\n",
    "                \n",
    "                # Print summary\n",
    "                print(f\"\\n       Results Summary:\")\n",
    "                for model_type in config.MODELS_TO_TRAIN:\n",
    "                    model_results = results['models'][model_type]\n",
    "                    mean_auc = np.mean(model_results['auc_roc'])\n",
    "                    mean_f1 = np.mean(model_results['f1'])\n",
    "                    print(f\"         {model_type:10s}: AUC={mean_auc:.4f}, F1={mean_f1:.4f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"       Error: {str(e)}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                all_results[tower_name][event_col] = {'error': str(e)}\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\" ALL TOWER-EVENT COMBINATIONS PROCESSED\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "\n",
    "# ==================== SAVE RESULTS ====================\n",
    "def save_all_results(all_results: Dict, config: DeepLearningConfig):\n",
    "    \"\"\"Save all experiment results with comprehensive summaries\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    output_dir = Path(f\"deep_learning_results_{timestamp}\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    models_dir = output_dir / \"models\"\n",
    "    models_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # In save_all_results function, replace gru_params/lstm_params with:\n",
    "    config_dict = {\n",
    "        'experiment': {\n",
    "            'timestamp': timestamp,\n",
    "            'description': 'Multi-event temporal forecasting with deep learning (CNN & TCN)'\n",
    "        },\n",
    "        'events': {\n",
    "            'target_events': config.TARGET_EVENTS,\n",
    "            'horizon': config.SELECTED_HORIZON,\n",
    "            'horizon_steps': config.FORECAST_HORIZONS[config.SELECTED_HORIZON]\n",
    "        },\n",
    "        'features': {\n",
    "            'description': 'Raw features only - CNN/TCN learn temporal patterns from sequences'\n",
    "        },\n",
    "        'models': {\n",
    "            'models_trained': config.MODELS_TO_TRAIN,\n",
    "            'n_splits': config.N_SPLITS,\n",
    "            'use_class_weights': config.USE_CLASS_WEIGHTS,\n",
    "            'device': config.DEVICE,\n",
    "            'sequence_length': config.SEQUENCE_LENGTH,\n",
    "            'batch_size': config.BATCH_SIZE,\n",
    "            'learning_rate': config.LEARNING_RATE,\n",
    "            'num_epochs': config.NUM_EPOCHS\n",
    "        },\n",
    "        'cnn_params': config.CNN_PARAMS,\n",
    "        'tcn_params': config.TCN_PARAMS,\n",
    "        'metrics': config.CLASSIFICATION_METRICS\n",
    "    }\n",
    "\n",
    "    \n",
    "    # # Save configuration\n",
    "    # config_dict = {\n",
    "    #     'experiment': {\n",
    "    #         'timestamp': timestamp,\n",
    "    #         'description': 'Multi-event temporal forecasting with deep learning (GRU & LSTM)'\n",
    "    #     },\n",
    "    #     'events': {\n",
    "    #         'target_events': config.TARGET_EVENTS,\n",
    "    #         'horizon': config.SELECTED_HORIZON,\n",
    "    #         'horizon_steps': config.FORECAST_HORIZONS[config.SELECTED_HORIZON]\n",
    "    #     },\n",
    "    #     'features': {\n",
    "    #         'lag_config': config.SELECTED_LAG_CONFIG,\n",
    "    #         'lags': config.LAG_CONFIGS[config.SELECTED_LAG_CONFIG],\n",
    "    #         'rolling_windows': config.ROLLING_WINDOWS\n",
    "    #     },\n",
    "    #     'models': {\n",
    "    #         'models_trained': config.MODELS_TO_TRAIN,\n",
    "    #         'n_splits': config.N_SPLITS,\n",
    "    #         'use_class_weights': config.USE_CLASS_WEIGHTS,\n",
    "    #         'device': config.DEVICE,\n",
    "    #         'sequence_length': config.SEQUENCE_LENGTH,\n",
    "    #         'batch_size': config.BATCH_SIZE,\n",
    "    #         'learning_rate': config.LEARNING_RATE,\n",
    "    #         'num_epochs': config.NUM_EPOCHS\n",
    "    #     },\n",
    "    #     'gru_params': config.GRU_PARAMS,\n",
    "    #     'lstm_params': config.LSTM_PARAMS,\n",
    "    #     'metrics': config.CLASSIFICATION_METRICS\n",
    "    # }\n",
    "    \n",
    "    with open(output_dir / 'config.json', 'w') as f:\n",
    "        json.dump(config_dict, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n Configuration saved to: {output_dir / 'config.json'}\")\n",
    "    \n",
    "    # Create summary\n",
    "    summary_data = []\n",
    "    for tower, tower_results in all_results.items():\n",
    "        for event, event_results in tower_results.items():\n",
    "            if 'error' not in event_results:\n",
    "                row = {\n",
    "                    'tower': tower,\n",
    "                    'event': event,\n",
    "                    'n_samples': event_results['n_samples'],\n",
    "                    'event_rate': event_results['event_rate']\n",
    "                }\n",
    "                \n",
    "                for model_type in config.MODELS_TO_TRAIN:\n",
    "                    model_results = event_results['results']['models'][model_type]\n",
    "                    \n",
    "                    for metric in config.CLASSIFICATION_METRICS:\n",
    "                        if metric in model_results:\n",
    "                            values = model_results[metric]\n",
    "                            row[f'{model_type}_{metric}_mean'] = np.mean(values)\n",
    "                            row[f'{model_type}_{metric}_std'] = np.std(values)\n",
    "                    \n",
    "                    for cm_comp in ['true_positives', 'true_negatives', 'false_positives', 'false_negatives']:\n",
    "                        if cm_comp in model_results:\n",
    "                            row[f'{model_type}_{cm_comp}_mean'] = np.mean(model_results[cm_comp])\n",
    "                \n",
    "                summary_data.append(row)\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    summary_df.to_csv(output_dir / 'summary_results.csv', index=False)\n",
    "    print(f\" Summary results saved to: {output_dir / 'summary_results.csv'}\")\n",
    "    \n",
    "    # ==================== PER-EVENT SUMMARY ====================\n",
    "    print(\"\\n Creating per-event best models summary...\")\n",
    "    per_event_summary = []\n",
    "    \n",
    "    for event in config.TARGET_EVENTS:\n",
    "        event_subset = summary_df[summary_df['event'] == event]\n",
    "        \n",
    "        if len(event_subset) == 0:\n",
    "            continue\n",
    "        \n",
    "        event_summary = {\n",
    "            'event': event,\n",
    "            'n_towers': event_subset['tower'].nunique(),\n",
    "            'total_samples': event_subset['n_samples'].sum(),\n",
    "            'avg_event_rate': event_subset['event_rate'].mean()\n",
    "        }\n",
    "        \n",
    "        for model_type in config.MODELS_TO_TRAIN:\n",
    "            for metric in config.CLASSIFICATION_METRICS:\n",
    "                metric_col = f'{model_type}_{metric}_mean'\n",
    "                \n",
    "                if metric_col in event_subset.columns:\n",
    "                    best_idx = event_subset[metric_col].idxmax()\n",
    "                    best_row = event_subset.loc[best_idx]\n",
    "                    \n",
    "                    event_summary[f'{model_type}_best_{metric}'] = best_row[metric_col]\n",
    "                    event_summary[f'{model_type}_best_{metric}_tower'] = best_row['tower']\n",
    "            \n",
    "            for metric in config.CLASSIFICATION_METRICS:\n",
    "                metric_col = f'{model_type}_{metric}_mean'\n",
    "                if metric_col in event_subset.columns:\n",
    "                    event_summary[f'{model_type}_avg_{metric}'] = event_subset[metric_col].mean()\n",
    "                    event_summary[f'{model_type}_std_{metric}'] = event_subset[metric_col].std()\n",
    "        \n",
    "        per_event_summary.append(event_summary)\n",
    "    \n",
    "    per_event_df = pd.DataFrame(per_event_summary)\n",
    "    per_event_df.to_csv(output_dir / 'best_models_per_event.csv', index=False)\n",
    "    print(f\" Per-event best models saved to: {output_dir / 'best_models_per_event.csv'}\")\n",
    "    \n",
    "    # ==================== PER-TOWER SUMMARY ====================\n",
    "    print(\"\\n Creating per-tower best models summary...\")\n",
    "    per_tower_summary = []\n",
    "    \n",
    "    for tower in summary_df['tower'].unique():\n",
    "        tower_subset = summary_df[summary_df['tower'] == tower]\n",
    "        \n",
    "        tower_summary = {\n",
    "            'tower': tower,\n",
    "            'n_events': tower_subset['event'].nunique(),\n",
    "            'total_samples': tower_subset['n_samples'].sum(),\n",
    "            'avg_event_rate': tower_subset['event_rate'].mean()\n",
    "        }\n",
    "        \n",
    "        for model_type in config.MODELS_TO_TRAIN:\n",
    "            for metric in config.CLASSIFICATION_METRICS:\n",
    "                metric_col = f'{model_type}_{metric}_mean'\n",
    "                \n",
    "                if metric_col in tower_subset.columns:\n",
    "                    best_idx = tower_subset[metric_col].idxmax()\n",
    "                    best_row = tower_subset.loc[best_idx]\n",
    "                    \n",
    "                    tower_summary[f'{model_type}_best_{metric}'] = best_row[metric_col]\n",
    "                    tower_summary[f'{model_type}_best_{metric}_event'] = best_row['event']\n",
    "            \n",
    "            for metric in config.CLASSIFICATION_METRICS:\n",
    "                metric_col = f'{model_type}_{metric}_mean'\n",
    "                if metric_col in tower_subset.columns:\n",
    "                    tower_summary[f'{model_type}_avg_{metric}'] = tower_subset[metric_col].mean()\n",
    "                    tower_summary[f'{model_type}_std_{metric}'] = tower_subset[metric_col].std()\n",
    "        \n",
    "        per_tower_summary.append(tower_summary)\n",
    "    \n",
    "    per_tower_df = pd.DataFrame(per_tower_summary)\n",
    "    per_tower_df.to_csv(output_dir / 'best_models_per_tower.csv', index=False)\n",
    "    print(f\" Per-tower best models saved to: {output_dir / 'best_models_per_tower.csv'}\")\n",
    "    \n",
    "    # ==================== PER-TOWER-EVENT SUMMARY ====================\n",
    "    print(\"\\n Creating per-tower-event best models summary...\")\n",
    "    per_tower_event_summary = []\n",
    "    \n",
    "    for tower in summary_df['tower'].unique():\n",
    "        for event in config.TARGET_EVENTS:\n",
    "            subset = summary_df[(summary_df['tower'] == tower) & (summary_df['event'] == event)]\n",
    "            \n",
    "            if len(subset) == 0:\n",
    "                continue\n",
    "            \n",
    "            row = subset.iloc[0]\n",
    "            \n",
    "            tower_event_summary = {\n",
    "                'tower': tower,\n",
    "                'event': event,\n",
    "                'n_samples': row['n_samples'],\n",
    "                'event_rate': row['event_rate']\n",
    "            }\n",
    "            \n",
    "            for model_type in config.MODELS_TO_TRAIN:\n",
    "                for metric in config.CLASSIFICATION_METRICS:\n",
    "                    metric_col = f'{model_type}_{metric}_mean'\n",
    "                    if metric_col in row.index:\n",
    "                        tower_event_summary[f'{model_type}_{metric}'] = row[metric_col]\n",
    "            \n",
    "            # Determine which model is better\n",
    "            gru_auc = row.get('gru_auc_roc_mean', 0)\n",
    "            lstm_auc = row.get('lstm_auc_roc_mean', 0)\n",
    "            \n",
    "            tower_event_summary['best_model'] = 'gru' if gru_auc >= lstm_auc else 'lstm'\n",
    "            tower_event_summary['best_auc'] = max(gru_auc, lstm_auc)\n",
    "            \n",
    "            per_tower_event_summary.append(tower_event_summary)\n",
    "    \n",
    "    per_tower_event_df = pd.DataFrame(per_tower_event_summary)\n",
    "    per_tower_event_df.to_csv(output_dir / 'best_models_per_tower_event.csv', index=False)\n",
    "    print(f\" Per-tower-event best models saved to: {output_dir / 'best_models_per_tower_event.csv'}\")\n",
    "    \n",
    "    # ==================== DETAILED TEXT REPORT ====================\n",
    "    report_file = output_dir / 'experiment_report.txt'\n",
    "    \n",
    "    with open(report_file, 'w') as f:\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(\"MULTI-EVENT TEMPORAL FORECASTING - DEEP LEARNING REPORT\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(f\"Timestamp: {timestamp}\\n\")\n",
    "        f.write(f\"Models: {', '.join(config.MODELS_TO_TRAIN)}\\n\")\n",
    "        f.write(f\"Forecast Horizon: {config.SELECTED_HORIZON} ({config.FORECAST_HORIZONS[config.SELECTED_HORIZON]} steps)\\n\")\n",
    "        f.write(f\"Sequence Length: {config.SEQUENCE_LENGTH}\\n\")\n",
    "        f.write(f\"Cross-validation folds: {config.N_SPLITS}\\n\")\n",
    "        f.write(f\"Total experiments: {len(summary_df)}\\n\\n\")\n",
    "        \n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(\"OVERALL PERFORMANCE SUMMARY\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        \n",
    "        for model_type in config.MODELS_TO_TRAIN:\n",
    "            f.write(f\"\\n{model_type.upper()} MODEL\\n\")\n",
    "            f.write(\"-\"*80 + \"\\n\")\n",
    "            \n",
    "            for metric in config.CLASSIFICATION_METRICS:\n",
    "                mean_col = f'{model_type}_{metric}_mean'\n",
    "                \n",
    "                if mean_col in summary_df.columns:\n",
    "                    mean_val = summary_df[mean_col].mean()\n",
    "                    std_val = summary_df[mean_col].std()\n",
    "                    max_val = summary_df[mean_col].max()\n",
    "                    min_val = summary_df[mean_col].min()\n",
    "                    \n",
    "                    f.write(f\"  {metric:20s}: {mean_val:.4f}  {std_val:.4f}  \"\n",
    "                           f\"[{min_val:.4f}, {max_val:.4f}]\\n\")\n",
    "            \n",
    "            f.write(\"\\n\")\n",
    "        \n",
    "        # Rankings\n",
    "        f.write(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "        f.write(\"ALL CONFIGURATIONS RANKED BY AUC-ROC\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        \n",
    "        for model_type in config.MODELS_TO_TRAIN:\n",
    "            f.write(f\"\\n{model_type.upper()}\\n\")\n",
    "            f.write(\"-\"*80 + \"\\n\")\n",
    "            \n",
    "            metric_col = f'{model_type}_auc_roc_mean'\n",
    "            if metric_col in summary_df.columns:\n",
    "                all_configs = summary_df.sort_values(metric_col, ascending=False)\n",
    "                \n",
    "                f.write(f\"{'Rank':<6} {'Tower':<8} {'Event':<35} {'AUC':<8} {'F1':<8} {'Event%':<8}\\n\")\n",
    "                f.write(\"-\"*80 + \"\\n\")\n",
    "                \n",
    "                for rank, (idx, row) in enumerate(all_configs.iterrows(), 1):\n",
    "                    event_display = row['event'].replace('event_', '')\n",
    "                    f.write(f\"{rank:<6} {row['tower']:<8} {event_display:<35} \"\n",
    "                           f\"{row[metric_col]:<8.4f} \"\n",
    "                           f\"{row[f'{model_type}_f1_mean']:<8.4f} \"\n",
    "                           f\"{row['event_rate']*100:<8.1f}\\n\")\n",
    "                \n",
    "                f.write(\"\\n\")\n",
    "    \n",
    "    print(f\" Experiment report saved to: {output_dir / 'experiment_report.txt'}\")\n",
    "    \n",
    "    # Save models\n",
    "    for tower, tower_results in all_results.items():\n",
    "        for event, event_results in tower_results.items():\n",
    "            if 'error' in event_results:\n",
    "                continue\n",
    "            \n",
    "            for model_type in config.MODELS_TO_TRAIN:\n",
    "                model_data = event_results['results']['models'][model_type]\n",
    "                \n",
    "                for fold_idx, model in enumerate(model_data['trained_models'], 1):\n",
    "                    model_filename = f\"{tower}_{event}_{model_type}_fold{fold_idx}.pt\"\n",
    "                    model_path = models_dir / model_filename\n",
    "                    \n",
    "                    torch.save({\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'model_type': model_type,\n",
    "                        'tower': tower,\n",
    "                        'event': event,\n",
    "                        'fold': fold_idx\n",
    "                    }, model_path)\n",
    "    \n",
    "    print(f\" Models saved to: {models_dir}/ ({len(list(models_dir.glob('*.pt')))} files)\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\" ALL RESULTS SAVED TO: {output_dir}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return output_dir\n",
    "\n",
    "\n",
    "# ==================== MAIN EXECUTION ====================\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'  #  Force only GPU 1 to be visible\n",
    "\n",
    "config = DeepLearningConfig()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MULTI-EVENT TEMPORAL FORECASTING - DEEP LEARNING\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Device: {config.DEVICE}\")\n",
    "print(f\"Batch size: {config.BATCH_SIZE}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Clear GPU memory before starting\n",
    "clear_gpu_memory()\n",
    "get_gpu_memory_info()\n",
    "\n",
    "# Run experiments\n",
    "all_results = run_multi_event_experiments(filtered_dfs, config)\n",
    "\n",
    "\n",
    "# Save results\n",
    "output_dir = save_all_results(all_results, config)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" DEEP LEARNING EXPERIMENTS COMPLETE!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
